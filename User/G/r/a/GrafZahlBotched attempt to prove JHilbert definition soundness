{{header
 | title    = Definition soundness of first-order logic in JHilbert
 | subtitle = 
 | left     = 
 | right    = 
 | shortcut = 
 | notes    = Attempt at a formal proof of soundness of first-order logic in JHilbert.
}}

== JHilbert ==

=== Names ===

'''Definition.''' <math>\Sigma</math> is a [[w:finite set|finite]], [[w:empty set|non-empty]] [[w:set (mathematics)|set]], the ''characters''.

'''Definition.''' <math>N:=\Sigma^*\setminus\{\epsilon\}</math>, that is, the set of all non-empty, finite [[w:sequence|sequence]]s of characters is the set of ''names''.

'''Lemma 1.''' The set of names <math>N</math> is [[w:countably infinite|countably infinite]].

{{sc|Proof.}} <math>N</math> is infinite because <math>\Sigma\neq\emptyset</math>, and countable because <math>\Sigma</math> is finite.

=== Kinds ===

'''Definition.''' The ''kinds'' are a [[w:tuple|tuple]] <math>(K,\sim)</math> where <math>K\subseteq N</math> is finite and <math>\sim</math> is an [[w:equivalence relation|equivalence relation]] on <math>K</math>. We denote the set <math>K/\sim</math> of all [[w:equivalence class|equivalence class]]es by <math>\mathcal{K}</math>.

Where no confusion is possible, we shall not distinguish between kinds and equivalence classes of kinds.

'''Explanation.''' <math>K</math> and <math>\sim</math> are user-defined in JHilbert through the <code>kind</code> and <code>kindbind</code> commands. The <code>kind</code> command adds a new name to <math>K</math> which initially is equivalent only to itself. The <code>kindbind</code> command adds a relation between two kinds in <math>K</math> to <math>\sim</math> (possibly after adding a new name to <math>K</math>) and completes <math>\sim</math> by [[w:reflexive closure|reflexive]], [[w:symmetric closure|symmetric]] and [[w:transitive closure|transitive]] [[w:closure (mathematics)|closure]].

=== Variables ===

'''Definition.''' A tuple <math>(n,k)</math> with <math>n\in N</math> and <math>k\in\mathcal{K}</math> is a ''variable''. For each variable <math>v=(n,k)</math> we denote the [[w:projection (set theory)|projection]] <math>(n,k)\mapsto n</math>, the ''name of <math>v</math>'', by <math>N(v)</math>, and the projection <math>(n,k)\mapsto k</math>, the ''kind of <math>v</math>'', by <math>K(v)</math>.

'''Definition.''' A finite set <math>V</math> is called a ''permissible set of variables'' if all elements of <math>V</math> are variables, and the [[w:restriction (mathematics)|restriction]] of the name projection <math>N</math> to <math>V</math> is [[w:injective|injective]].

'''Lemma 2.''' Let <math>V</math> be a permissible set of variables. Then any <math>W\subseteq V</math> is also a permissible set of variables.

{{sc|Proof.}} <math>W</math> is finite since <math>V</math> is finite. <math>W</math> contains only variables since <math>W</math> is contained in <math>V</math>. Finally, the restriction of an injective function remains injective.

'''Theorem 1.''' Let <math>V</math> be a permissible set of variables. Then for any <math>k\in\mathcal{K}</math> there is a <math>n\in N</math> such that <math>(n,k)\notin V</math> and <math>V':=V\cup\{(n,k)\}</math> is a permissible set of variables.

{{sc|Proof.}} Since <math>V</math> is finite, the image <math>N(V)</math> is finite as well. Now, <math>N</math> is infinite by Lemma 1. Therefore, there exists an <math>n\in N\setminus N(V)</math>. Since <math>n\notin (\left.N\right|_V)^{-1}(N)</math>, <math>(n,k)\notin V</math>. <math>V'</math> is finite because <math>V</math> and the singleton <math>\{(n,k)\}</math> are finite, and <math>(n,k)</math> is clearly a variable. Again, since <math>n\notin (\left.N\right|_V)^{-1}(N)</math>, <math>N((n,k))\neq N(v)</math> for all <math>v\in V</math>. Therefore, the name projection is injective on <math>V'</math>.

'''Definition.''' The ''variables'' are a permissible set of variables <math>V</math>. It is [[w:partition of a set|partitioned]] into three subsets, the ''named variables'' <math>V_N</math>, the ''unnamed variables'' <math>V_U</math> and the ''dummy variables'' <math>V_D</math>. By Lemma 2, these subsets are also permissible sets of variables.

'''Explanation.''' The named variables <math>V_N</math> are user-defined in JHilbert through the <code>var</code> command. Unnamed variables and dummy variables are automatically introduced as explained later. Since the empty set is a permissible set of variables, Theorem 1 ensures that such automatic introduction of new variables is always possible. In fact, JHilbert cheats a little by extending <math>\Sigma</math> for this purpose, so the namespace for user-defined variables doesn't become polluted.

=== Functors ===

'''Definition.''' A tuple <math>(n,k,l)</math> with <math>n\in N</math>, <math>k\in\mathcal{K}</math> and <math>l\in\mathcal{K}^*</math> is a ''functor''. For each functor <math>f=(n,k,l)</math>, we denote the projection <math>(n,k,l)\mapsto n</math>, the ''name of <math>f</math>'', by <math>N(f)</math>, and the projection <math>(n,k,l)\mapsto k</math>, the ''kind of <math>f</math>'', by <math>K(f)</math>. Furthermore, we denote the function <math>(n,k,l)\mapsto|l|</math>, where <math>|l|</math> is the length of the sequence <math>l</math>, the ''place count of <math>f</math>'', by <math>PC(f)</math>. For each <math>i\in\mathbb{N}</math>, <math>1\leq i\leq PC(f)</math>, we denote by <math>IK_i(f)</math> the mapping of <math>(n,k,l)</math> to the <math>i</math>-th projection of <math>l</math>. We call <math>IK_i(f)</math> the ''<math>i</math>-th input kind of <math>f</math>.''

'''Definition.''' A finite set <math>F</math> is called a ''permissible set of functors'' if all elements of <math>F</math> are functors and the restriction of the name projection <math>N</math> to <math>F</math> is injective.

'''Lemma 3.''' Let <math>F</math> be a permissible set of functors. Then any <math>G\subseteq F</math> is also a permissible set of functors.

{{sc|Proof.}} The proof is similar to the proof of Lemma 2.

'''Definition.''' The ''functors'' are a permissible set of functors <math>F</math>.

=== Term functors ===

'''Definition.''' The ''term functors'' are a set <math>F_T\subseteq F</math>. By Lemma 3, term functors are a permissible set of functors.

'''Explanation.''' Term functors are user-defined in JHilbert through the <code>term</code> command. However, they are not the only functors as definitions (see below) give rise to further functors.

=== Expressions ===

'''Definition.''' We define when some element <math>e</math> is an ''expression'', and what the ''kind of <math>e</math>'', <math>K(e)</math>, is, [[w:recursive definition|recursively]] as follows:
# If <math>e\in V</math> then <math>e</math> is an expression. (In this case, <math>K(e)</math> is defined by the definition of the kind of a variable.)
# If <math>e=(f,s)</math> where <math>f\in F</math> and <math>s</math> is a finite sequence of expressions such that <math>PC(f)=|s|</math> and for <math>i=1,\ldots,|s|</math> the <math>i</math>-th element of <math>s</math>, <math>s_i</math>, fulfils the equation <math>IK_i(f)=K(s_i)</math>, then <math>e</math> is an expression.
# Nothing else is an expression.
# If <math>e=(f,s)</math> is an expression, then <math>K(e)=K(f)</math>.
We denote the set of all expressions by <math>E(V,F)</math>.

'''Lemma 4.''' The set <math>E(V,F)</math> is either finite or countably infinite.

{{sc|Proof.}} By using [[w:polish notation|polish notation]] we may consider <math>E(V,F)</math> a subset of <math>(V\cup F)^*</math>. Since both <math>V</math> and <math>F</math> are finite, that set is finite or countably infinite. Hence <math>E(V,F)</math> is finite or countably infinite.

'''Definition.''' Let <math>e\in E(V,F)</math>. Then we define the ''length of <math>e</math>'', <math>|e|</math> recursively as follows:
# If <math>e\in V</math> then <math>|e|=1</math>.
# If <math>e=(f,s)</math> then <math>|e|</math> is the sum of the lengths of the expressions in <math>s</math>, plus one.

'''Lemma 5.''' Let <math>e\in E(V,F)</math>. Then <math>|e|=1</math> if and only if either <math>e\in V</math> or <math>e=(f,s)</math> with <math>PC(f)=0</math> and hence <math>s=\epsilon</math>.

{{sc|Proof.}} If <math>e\in V</math> or <math>e=(f,s)</math> with the stated properties then clearly <math>|e|=1</math>. Now assume <math>e=(f,s)</math> with <math>PC(f)\neq 0</math>. But then surely <math>|e|>1</math> since all expressions in <math>s</math> have length at least one.

'''Definition.''' Let <math>e_1,e_2\in E(V,F)</math>. Then we define when <math>e_2</math> is a ''subexpression'' of <math>e_1</math> recursively as follows.
# If <math>e_1\in V</math> then <math>e_2</math> is a subexpression of <math>e_1</math> if and only if <math>e_1=e_2</math>.
# If <math>e_1=(f,s)</math> then <math>e_2</math> is a subexpression of <math>e_1</math> if and only if either <math>e_1=e_2</math> or <math>e_2</math> is a subexpression of one of the expressions in <math>s</math>.

'''Lemma 6.''' Let <math>e_1\in E(V,F)</math> and let <math>e_2</math> be a subexpression of <math>e_1</math>. Then <math>|e_2|\leq|e_1|</math> and equality holds if and only if <math>e_1=e_2</math>.

{{sc|Proof.}} This follows from the strict [[w:monotonicity|monotonicity]] of the addition of [[w:positive integer|positive integer]]s.

'''Definition.''' Let <math>e\in E(V,F)</math> and <math>f\in F</math>. We define when <math>f</math> is ''apparent'' in <math>e</math> recursively as follows:
# If <math>e=(f',\epsilon)</math> then <math>f</math> is apparent in <math>e</math> if and only if <math>f=f'</math>.
# If <math>e=(f',s)</math> then <math>f</math> is apparent in <math>e</math> if and only if either <math>f=f'</math> or <math>f</math> is apparent in at least one of the expressions in <math>s</math>.
# In no other case is <math>f</math> apparent in <math>e</math>.

'''Definition.''' Let <math>e\in E(V,F)</math> and <math>v\in V</math>. We define when <math>v</math> is ''apparent'' in <math>e</math> recursively as follows:
# If <math>e\in V</math> then <math>v</math> is apparent in <math>e</math> if and only if <math>e=v</math>.
# If <math>e=(f,s)</math> then <math>v</math> is apparent in <math>e</math> if and only if it is apparent in at least one of the expressions in <math>s</math>.
We denote the set of apparent variables of <math>e</math> by <math>A(e)</math>.

'''Definition.''' Let <math>e\in E(V,F)</math> and let <math>v_1,v_2\in A(e)</math>. We define when <math>v_1\leq_e v_2</math> recursively as follows:
# If <math>e\in V</math> then <math>v_1\leq_e v_2</math>.
# If <math>e=(f,s)</math> and there is an expression <math>e_1</math> in <math>s</math> such that
#:* <math>v_1\in A(e_1)</math>,
#:* <math>v_2\notin A(e')</math> for all expressions <math>e'</math> before <math>e_1</math> in <math>s</math>,
#:* <math>v_2\notin A(e_1)</math> or <math>v_1\leq_{e_1} v_2</math>,
#:then <math>v_1\leq_e v_2</math>.
# <math>v_1\leq_e v_2</math> in no other case.

'''Lemma 7.''' Let <math>e\in E(V,F)</math>. Then <math>(A(e),\leq_e)</math> is a [[w:total order|totally ordered]] set.

{{sc|Proof.}} We prove this by [[w:mathematical induction|induction]] over <math>|e|</math>. First, if <math>|e|=1</math> then by Lemma 5 either <math>A(e)=\emptyset</math> in which case there is nothing to prove, or <math>A(e)</math> contains only one element. Since <math>\leq_e</math> is obviously reflexive, [[w:antisymmetric relation|antisymmetry]], transitivity and [[w:total relation|totality]] follow in this case. Now assume <math>|e|>1</math> (that is <math>e=(f,s)</math>) and let the statement be proven for all expressions of length smaller than <math>|e|</math>. Now let <math>v_1,v_2\in A(e)</math> and assume <math>v_1\not\leq_e v_2</math>. Since <math>v_2\in A(e)</math>, there is an expression <math>e_1</math> in <math>s</math> such that <math>v_2\in A(e_1)</math>. Since the [[w:natural number|natural number]]s are [[w:well-order|well-order]]ed, we may assume <math>e_1</math> to be the leftmost such expression in <math>s</math>. Now, if there was an expression <math>e'</math> in <math>s</math> before <math>e_1</math>, then <math>v_1\leq_e v_2</math>, which we have excluded. Since <math>v_1\in A(e)</math>, either <math>v_1\in A(e')</math> for some <math>e'</math> after <math>e_1</math> in <math>s</math>, in which case <math>v_2\leq_e v_1</math> follows, or <math>v_1\in A(e_1)</math>, which case again <math>v_2\leq_e v_1</math> since by induction hypothesis <math>\leq_{e_1}</math> is total. This establishes the totality of <math>\leq_e</math>. Next, assume both <math>v_1\leq_e v_2</math> and <math>v_2\leq_e v_1</math>. Then by similar reasoning as above, <math>v_1,v_2\in A(e_1)</math> and antisymmetry follows since <math>\leq_{e_1}</math> is antisymmetric by induction hypothesis, so <math>\leq_e</math> is antisymmetric. Finally, let <math>v_3\in A(e)</math> and assume <math>v_1\leq_e v_2</math> and <math>v_2\leq _e v_3</math>. As above, let <math>e_1,e_2,e_3</math> the respective leftmost expressions in <math>s</math> such that <math>v_i\in A(e_i)</math>, <math>i=1,2,3</math>. Since <math>v_1\leq_e v_2</math>, <math>e_2</math> cannot come before <math>e_1</math> in <math>s</math>. Similarly, <math>e_3</math> cannot come before <math>e_2</math> in <math>s</math>. Therefore, <math>e_3</math> cannot come before <math>e_1</math> in <math>s</math>. If <math>e_1</math> comes before <math>e_3</math> then <math>v_1\leq_e v_3</math>. Otherwise <math>e_1=e_3</math> and <math>v_1\leq_e v_3</math> follows since <math>\leq_{e_1}=\leq_{e_3}</math> is transitive by induction hypothesis. This establishes the transitivity of <math>\leq_e</math> and thus finishes the proof.

'''Definition.''' Let <math>W\subseteq V</math> and <math>u\colon W\to E(V,F)</math> a map such that all <math>w\in W</math> fulfil the equation <math>K(w)=K(u(w))</math>. Then <math>u</math> is called a ''proper substitution map''. We also define the ''extension'' <math>\tilde{u}</math> of <math>u</math> on <math>E(V,F)</math> recursively by
# <math>\tilde{u}(w)=u(w)</math> for all <math>w\in W</math>,
# <math>\tilde{u}(v)=v</math> for all <math>v\in V\setminus W</math>,
# <math>\tilde{u}((f,(e_1,\ldots,e_n)))=(f,(\tilde{u}(e_1),\ldots,\tilde{u}(e_2)))</math> for all <math>(f,(e_1,\ldots,e_n))\in E(V,F)\setminus V</math>.

'''Lemma 8.''' Let <math>u\colon W\to E(V,F)</math> be a proper substitution map. Then the image of the extension <math>\tilde{u}(E(V,F))\subseteq E(V,F)</math> and for all <math>e\in E(V,F)</math> the equation <math>K(e)=K(\tilde{u}(e))</math> holds.

{{sc|Proof.}} Let <math>e\in E(V,F)</math>. We have to show that <math>\tilde{u}(e)\in E(V,F)</math> and <math>K(e)=K(\tilde{u}(e))</math>. We prove this by induction over <math>|e|</math>. First, assume <math>|e|=1</math>. Then either <math>e=(f,\epsilon)</math> in which case <math>\tilde{u}(e)=e</math>, or <math>e\in V</math>. If <math>e\in V\setminus W</math> then again <math>\tilde{u}(e)=e</math>. If <math>e\in W</math> then <math>\tilde{u}(e)=u(e)\in E(V,F)</math> and <math>K(\tilde{u}(e))=K(u(e))=K(e)</math> by the definition of a proper substitution map. This proves the statement for <math>|e|=1</math>. Now assume the statement proven for all expressions of length smaller than <math>|e|>1</math>. Then <math>e=(f,(e_1,\ldots,e_n))</math>. By the induction hypothesis, <math>(\tilde{u}(e_1),\ldots,\tilde{u}(e_n))</math> is a sequence of expressions. Its length is equal to the length of <math>(e_1,\ldots,e_n)</math>. The induction hypothesis also implies that for <math>i=1,\ldots,n</math> we have <math>IK_i(f)=K(e_i)=K(\tilde{u}(e_i))</math>. Therefore <math>\tilde{u}(e)\in E(V,F)</math>. Since <math>K(\tilde{u}(e))=K(f)</math> and <math>K(e)=K(f)</math>, the statement is proven.

'''Lemma 9.''' Let <math>u\colon W\to E(V,F)</math> be a proper substitution map and <math>W'\subseteq W</math>. Then the restriction <math>\left.u\right|_{W'}</math> is also a proper substitution map and <math>\tilde{u}(e)=(\left.u\right|_{W'})^\sim(e)</math> for all <math>e\in E(V,K)</math> with <math>A(e)\subseteq W'</math>.

{{sc|Proof.}} That <math>\left.u\right|_{W'}</math> is also a proper substitution map is clear from the definition. Now let <math>e\in E(V,F)</math> such that <math>A(e)\subseteq W'</math>. We prove the remainder of the statement by induction over <math>|e|</math>. First, assume <math>|e|=1</math>. Then either <math>e=(f,\epsilon)</math> in which case the statement is clear, or <math>e\in V</math>, in which case it follows by <math>e\in W'</math>. Now, for the case <math>|e|>1</math> we have <math>e=(f,(e_1,\ldots,e_n))</math> and since clearly <math>A(e_i)\subseteq A(e)</math> for <math>i=1,\ldots,n</math>, the statement follows in this case also from the induction hypothesis.

'''Definition.''' Let <math>e_1,e_2\in E(V,F)</math>. Then <math>e_2</math> ''arises from <math>e_1</math> by proper substitution'' if there is a proper substitution map <math>u\colon A(e_1)\to E(V,F)</math> such that <math>\tilde{u}(e_1)=e_2</math>.

'''Lemma 10.''' Let <math>e_1=(f_1,(e_{11},\ldots,e_{1n}))</math> and <math>e_2=(f_2,(e_{21},\ldots,e_{2m}))</math> be expressions. Assume furthermore that <math>e_2</math> arises from <math>e_1</math> by proper substitution. Then <math>f_1=f_2</math>, <math>n=m</math> and if <math>u\colon A(e_1)\to E(V,F)</math> is a proper substitution map such that <math>\tilde{u}(e_1)=e_2</math> then <math>(\left. u\right|_{A(e_{1i})})^\sim(e_{1i})=e_{2i}</math> for all <math>i=1,\ldots,n</math>.

{{sc|Proof.}} That <math>f_1=f_2</math> and <math>n=m</math> is clear. The remainder of the statement follows from the definition of a proper substitution map and Lemma 9.

'''Lemma 11.''' Let <math>e_1,e_2\in E(V,F)</math> be such that <math>e_2</math> arises from <math>e_1</math> by proper substitution. Then the proper substitution map <math>u\colon A(e_1)\to E(V,F)</math> such that <math>\tilde{u}(e_1)=e_2</math> is [[w:unique|unique]].

{{sc|Proof.}} Assume there are two such maps <math>u_1,u_2\colon A(e_1)\to E(V,F)</math> which are different. Then there is a <math>v\in A(e_1)</math> such that <math>u_1(v)\neq u_2(v)</math>. We proceed with an induction over <math>|e_1|</math>. If <math>|e_1|=1</math>, then either <math>e_1=(f,\epsilon)</math> in which case <math>A(e_1)=\emptyset</math>, so <math>u_1,u_2</math> cannot be distinct, or <math>e_1\in V</math>. In this case, <math>e_1=v</math> since <math>v</math> is apparent in <math>e_1</math>. But then <math>u_1(e_1)\neq u_2(e_1)</math>, which is [[w:reductio ad absurdum|absurd]]. Now assume the statement proven for all expressions of length smaller than <math>|e_1|>1</math>. Then <math>e_1=(f,(e_{11},\ldots,e_{1n}))</math>, so there must be a positive integer <math>1\leq i\leq n</math> such that <math>\tilde{u}_1(e_{1i})\neq\tilde{u}_2(e_{1i})</math> since <math>v</math> must be apparent in one of the <math>e_{1i}</math>. But this contradicts the induction hypothesis in combination with Lemma 10.

'''Definition.''' Let <math>(f,s)</math> be an expression. Then <math>f</math> is called the ''head functor'' of <math>(f,s)</math>.

=== Definitions ===

'''Definition.''' We define the ''definition functors'' as <math>F_D:=F\setminus F_T</math>.

'''Definition.''' Let <math>l\in V^*</math>. Write <math>l=(v_1,\ldots,v_n)</math>. Then we set <math>K(l):=(K(v_1),\ldots,K(v_n))\in\mathcal{K}^*</math>.

'''Definition.''' Let <math>d=(n,l,e)</math> with <math>n\in N</math>, <math>l\in V_U^*</math> and <math>e\in E(V,K)</math> such that <math>F(d):=(n,K(e),K(l))\in F_D</math>. Assume furthermore that for all <math>v\in A(e)</math> either <math>v</math> occurs in <math>l</math> or <math>v\in V_D</math>. Then <math>d</math> is called a ''definition-like tuple''.

'''Definition.''' Let <math>D</math> be a set of definition-like tuples such that <math>F\colon D\to F_D</math> is [[w:bijective|bijective]]. Assume furthermore that there exists a function <math>\beta</math>, the ''depth'', defined on <math>F</math> and <math>E(V,F)</math>, with values in <math>\mathbb{Z}_{\geq 0}</math> such that all the following properties hold:
# <math>\beta(f)=0</math> for all <math>f\in F_T</math>.
# <math>\beta(v)=0</math> for all <math>v\in V</math>.
# For all <math>(f,s)\in E(V,F)\setminus V</math>, <math>\beta((f,s))=\beta(f)</math>.
# For all <math>f\in F_D</math> the definition-like tuple <math>F^{-1}(f)=(n,l,e)</math> fulfils the property that <math>\beta(f)>\beta(e')</math> for all subexpressions <math>e'</math> of <math>e</math>. Specifically, <math>\beta(f)=\beta(e)+1</math>.
# For each <math>v\in V_D</math> there is exactly one <math>f\in F_D</math> such that for the definition-like tuple <math>F^{-1}(f)=(n,l,e)</math> the property <math>v\in A(e)</math> holds.
Then <math>D</math> is called a ''valid set of definitions'' for <math>F_D</math>.

'''Explanation.''' The definitions of JHilbert, user-defined via the <code>def</code> command fulfil the above properties of a valid set of definitions. When new <code>def</code> commands are evaluated, <math>F_D</math>, <math>V_U</math> and <math>V_D</math> are grown accordingly. Theorem 1 ensures that this is always possible. There are, of course, many valid sets of definitions. From now on, we shall assume <math>D</math> to be one arbitrary such set.

'''Lemma 12.''' The set <math>D</math> is finite.

{{sc|Proof.}} Since, <math>F</math> is finite, so is <math>F_D</math>. The finiteness of <math>D</math> now follows from the bijectivity of <math>F\colon D\to F_D</math>.

'''Lemma 13.''' If <math>f\in F_D</math> then <math>\beta(f)>0</math>.

{{sc|Proof.}} This follows from the definition of <math>\beta</math>.

'''Definition.''' Let <math>e\in E(V,F)</math>. Then we define the ''maximum depth'' of <math>e</math> as <math>\hat{\beta}(e):=\max\beta(e')</math>, where <math>e'</math> runs over all subexpressions of <math>e</math>.

'''Definition.''' Let <math>e=(f,(e_1,\ldots,e_m))\in E(V,F)\setminus V</math> be an expression such that <math>f\in F_D</math> and let <math>(n,(v_1,\ldots,v_m),e')=F^{-1}(f)</math>. Define the proper substitution map <math>u</math> by setting <math>u(v_i)=e_i</math> for <math>i=1,\ldots,m</math>. Then <math>\tilde{u}(e')</math> is called the ''unfolding'' of <math>e</math>.

'''Lemma 14.''' Let <math>e_1,e_2\in E(V,F)</math>. If <math>e_2</math> is the unfolding of <math>e_1</math> then <math>\beta(e_1)=\beta(e_2)+1</math> and <math>\hat{\beta}(e_1)\geq\hat{\beta}(e_2)</math>.

{{sc|Proof.}} Since <math>e_1</math> has an unfolding, it has a head functor which is a definition functor. The first claim now results from the definition of <math>\beta</math>. The second claim follows since by the definition of <math>D</math>, all apparent functors of <math>e_2</math> which are not apparent functors of <math>e_1</math> have lower depth than <math>e_1</math>.

'''Definition.''' Let <math>e\in E(V,F)</math>. Then we define the ''complete unfolding'' of <math>e</math>, <math>CUF(e)</math> recursively as follows.
# If <math>e\in V</math> then <math>CUF(e)=e</math>.
# If <math>e=(f,(e_1,\ldots,e_m))</math> with <math>f\in F_T</math> then <math>CUF(e)=(f,(CUF(e_1),\ldots,CUF(e_m)))</math>.
# If the head functor of <math>e</math> is a definition functor and <math>e'</math> is the unfolding of <math>e</math> then <math>CUF(e)=CUF(e')</math>.
Lemma 14 ensures that the recursion in this definition terminates.

'''Lemma 15.''' Let <math>e\in E(V,F)</math>. Then all apparent functors of <math>CUF(e)</math> are term functors. In other words, <math>\hat{\beta}(e)=0</math>.

{{sc|Proof.}} Due to the definition of <math>CUF</math>, <math>\beta(f)=0</math> for all apparent functors of <math>e</math>. Hence the claim follows from Lemma 13.

'''Definition.''' We denote the subset of <math>E(V,F)</math> of expressions all of whose apparent functors are term functors by <math>E(V,F_T)</math>.

'''Lemma 16.''' <math>CUF</math> is an [[w:idempotent|idempotent]] operation.

{{sc|Proof.}} Let <math>e\in E(V,F_T)</math>. By Lemma 15 it is sufficient to show that <math>CUF(e)=e</math>. If <math>|e|=1</math>, this follows by direct calculation. Assume the statement proven for expressions of length smaller than <math>|e|>1</math>. Then <math>e=(f,(e_1,\ldots,e_m))</math> and <math>CUF(e)=CUF((f,(e_1,\ldots,e_m)))=(f,CUF(e_1),\ldots,CUF(e_m))=(f,(e_1,\ldots,e_m))=e</math> by induction hypothesis.

'''Definition.''' Let <math>e_1,e_2\in E(V,F)</math>. Then <math>e_1</math> and <math>e_2</math> are called ''D-equivalent'' if <math>CUF(e_1)=CUF(e_2)</math>.

'''Lemma 17.''' D-equivalence is an equivalence relation.

{{sc|Proof.}} Reflexivity and symmetry are clear. Transitivity follows from the uniqueness of the complete unfolding.

'''Definition.''' Let <math>e\in E(V,F)</math>. Then we denote the equivalence class of <math>e</math> with respect to D-equivalence by <math>[e]_D</math> and the set of all equivalence classes by <math>E(V,F)_D</math>.

'''Lemma 18.''' <math>E(V,F_T)</math> is a set of representatives for <math>E(V,F)_D</math>.

{{sc|Proof.}} Let <math>C\in E(V,F)_D</math>. Since D-equivalence is an equivalence relation, <math>C\neq\emptyset</math>. Therefore there exists an <math>e\in C</math>. Now <math>CUF(e)</math> and <math>e</math> are D-equivalent and <math>CUF(e)\in E(V,F_T)</math> by Lemma 15. Now let <math>e'\in E(V,F_T)</math> be another representative for <math>C</math>. By definition of D-equivalence, <math>CUF(e')=CUF(CUF(e))</math>. Since <math>e'\in E(V,F_T)</math> and due to idempotence <math>e'=CUF(e)</math>. This proves the lemma.

'''Lemma 19.''' Let <math>u</math> be a proper substitution map and let <math>e\in E(V,F)</math>. Then <math>\tilde{u}(e)</math> and <math>\tilde{u}(CUF(e))</math> are D-equivalent.

{{sc|Proof.}} This is clear if <math>e\in V</math>. If <math>e=(f,(e_1,\ldots,e_m))</math> with <math>\beta(f)=0</math> then <math>CUF(\tilde{u}(e))=(f,(CUF(\tilde{u}(e_1)),\ldots,CUF(\tilde{u}(e_m))))</math>, by induction over <math>|e|</math>, <math>=(f,(CUF(\tilde{u}(CUF(e_1))),\ldots,CUF(\tilde{u}(CUF(e_m)))))=CUF(\tilde{u}(CUF(e)))</math>. For the case <math>\beta(f)>0</math> assume the statement proven for all expressions of depth shallower than <math>e</math>. Let <math>e'</math> be the unfolding of <math>e</math>, then <math>\tilde{u}(e')</math> is the unfolding of <math>\tilde{u}(e)</math>, in particular <math>\beta(\tilde{u}(e))>\beta(\tilde{u}(e'))</math> and hence <math>CUF(\tilde{u}(e))=CUF(\tilde{u}(e'))=CUF(\tilde{u}(CUF(e')))=CUF(\tilde{u}(CUF(e)))</math> by induction hypothesis.

'''Lemma 20.''' Let <math>u</math> be a proper substitution map. Then <math>\tilde{u}</math> is well-defined on <math>E(V,F)_D</math>.

{{sc|Proof.}} Let <math>e_1,e_2</math> be D-equivalent. Then by Lemma 19 and D-equivalence <math>CUF(\tilde{u}(e_1))=CUF(\tilde{u}(CUF(e_1)))=CUF(\tilde{u}(CUF(e_2)))=CUF(\tilde{u}(e_2))</math>. This implies the lemma.

'''Definition.''' Let <math>e\in E(V,F)</math>. Then a variable <math>v\in V</math> ''occurs'' in <math>e</math> if <math>v\in A(CUF(e))</math>. We denote the set of all variables occurring in <math>e</math> by <math>O(e)</math>.

'''Lemma 21.''' Let <math>e\in E(V,F)</math>. Then <math>O(e)\setminus V_D\subseteq A(e)</math>.

{{sc|Proof.}} By the definition of <math>D</math>, the only new variables an unfolding of a subexpression of <math>e</math> can incur are dummy variables.

'''Definition.''' Let <math>e_1,\ldots,e_m,e_1',\ldots,e_m'\in E(V,F)_D</math>. Assume there is a proper substitution map <math>u</math> such that <math>u(e_i)=e_i'</math> for all <math>i=1,\ldots,m</math>. Then the <math>e_1,\ldots,e_m</math> are called ''simultaneously [[w:unification|unifiable]]'' with the <math>e_1',\ldots,e_m'</math>.

=== DV constraints ===

'''Definition.''' Let <math>A</math> be a set and <math>R\subseteq A\times A</math>. Then <math>R</math> is called ''self-avoiding'' if <math>(x,x)\notin R</math> for all <math>x\in A</math>.

'''Definition.''' Let <math>R\subseteq A\times A</math>. Then the set <math>R\setminus\{(x,x):x\in A\}</math> is called the ''self-avoiding aperture'' of <math>R</math>.

'''Lemma 22.''' Let <math>R\subseteq A\times A</math>. Furthermore, let <math>R_1</math> be the symmetric closure of the self-avoiding aperture of <math>R</math> and <math>R_2</math> the self-avoiding aperture of the symmetric closure of <math>R</math>. Then <math>R_1=R_2</math>.

{{sc|Proof.}} Let <math>(x,y)\in R_1</math>. Then <math>(x,y)\in R\setminus\{(x,x):x\in A\}</math> or <math>(y,x)\in R\setminus\{(x,x):x\in A\}</math>. In particular <math>x\neq y</math> and <math>(x,y)\in R</math> or <math>(y,x)\in R</math>. Therefore <math>(x,y)</math> is an element of the symmetric closure of <math>R</math>. Since <math>x\neq y</math>, <math>(x,y)\in R_2</math>. If, on the other hand, <math>(x,y)\in R_2</math>, then <math>x\neq y</math> and <math>(x,y)\in R</math> or <math>(y,x)\in R</math>. Therefore <math>(x,y)\in R_1</math>

'''Definition.''' A symmetric, self-avoiding relation on <math>V</math> is called a ''DV constraint''. A DV constraint on <math>V_N</math> is called a ''named DV constraint'' and a DV constraint on <math>V_U</math> is called an ''unnamed DV constraint''.

'''Definition.''' Let <math>\Delta</math> be a DV constraint. Then we define the set <math>A(\Delta):=\{v\in V:\exists w\in V:(v,w)\in\Delta\}</math>. Furthermore, if <math>W\subseteq V</math>, we define <math>\Delta_W:=\bigcup\limits_{\Delta'\subseteq\Delta}\Delta'</math>, where <math>\Delta'</math> runs over those DV constraints with <math>A(\Delta')\subseteq W</math>, the ''restriction'' of <math>\Delta</math> to <math>W</math>.

'''Lemma 23.''' Each restriction of a DV constraint is again a DV constraint, as is the union of two DV constraints. The same holds for named and unnamed DV constraints, respectively.

{{sc|Proof.}} This follows since the union of two self-avoiding relations is self-avoiding, and likewise the union of two symmetric relations is again symmetric.

=== Statements ===

'''Definition.''' A tuple <math>s=(n,\Delta,h,e)</math> with <math>n\in N</math>, <math>\Delta</math> a DV constraint, <math>h\in E(V,F)^*</math> and <math>e\in E(V,F)</math> is a ''statement'' if the following additional properties are fulfilled:
* <math>A(e)\subseteq V_U</math> and <math>A(e')\subseteq V_U</math> for all <math>e'</math> in <math>h</math>. In other words, <math>A(s)\subseteq V_U</math>, where we define <math>A(s):=A(e)\cup\bigcup\limits_{k=1}^{|h|}A(h_k)</math>,
* <math>A(\Delta)\subseteq A(s)</math>.
We we define the ''name'', <math>A(s):=n</math>, the ''DV constraints'' <math>DV(s):=\Delta</math>, the ''hypotheses'' <math>H(s):=h</math>, the ''number of hypotheses'' <math>NH(s):=|h|</math>, the <math>i</math>-th ''hypothesis'' <math>H_i(s)</math> as the <math>i</math>-th projection of <math>H(s)</math>, for <math>i=1,\ldots,NH(s)</math>, and the ''consequent'' <math>C(s):=e</math>.
If <math>s</math> fulfils precisely the same properties except that <math>V_U</math> is replaced by <math>V_N</math> then <math>s</math> is called a ''pending statement''.

'''Definition.''' A finite set <math>S</math> is called a ''permissible set of statements'' if all elements of <math>S</math> are statements and the restriction of the name projection <math>N</math> to <math>S</math> is injective.

'''Lemma 24.''' Let <math>S</math> be a permissible set of statements. Then any <math>S'\subseteq S</math> is also a permissible set of statements.

{{sc|Proof.}} The proof is similar to the proof of Lemma 2.

'''Explanation.''' First, statements are user-defined in JHilbert using the <code>stmt</code> and <code>thm</code> commands (where the <code>thm</code> statements have first to be derived as defined below). The user writes the statements as pending statements which are subsequently ''anonymised'' by introducing new unnamed variables that replace the named ones in the pending statement. Theorem 1 shows that this is always possible.

'''Definition.''' Let <math>s</math> be a pending statement and <math>e\in E(V,F)_D</math>. Assume there is a <math>W\subseteq V</math> with <math>W\cap A(s)=\emptyset</math> and an injective map <math>u\colon W\to V\setminus A(s)</math> which is a proper substitution map such that <math>\tilde{u}(e)=[C(s)]_D</math>. Then <math>C(s)</math> and <math>e</math> are called ''V-equivalent'' (with respect to <math>s</math>).

Note that V-equivalence is not an equivalence relation on <math>E(V,F)</math> (or <math>E(V,F)_D</math>) because it is a relation between different sets. Furthermore, the actual equivalence depends on the apparent variables in the statement. However, we can say that V-equivalence is coarser than D-equivalence in the following sense.

'''Lemma 25.''' Let <math>s</math> be a pending statement and let <math>e\in E(V,F)</math> be D-equivalent to <math>C(s)</math>. Then <math>C(s)</math> and <math>[e]_D</math> are V-equivalent.

{{sc|Proof.}} D-equivalence implies <math>[e]_D=[C(s)]_D</math>. Hence the requirement <math>\tilde{u}([e]_D)=[C(s)]_D</math> is fulfilled by an empty map <math>u</math>. Clearly, such a map fulfils the further requirements of V-equivalence. This proves the statement.

'''Definition.''' Let <math>s</math> be a pending statement. We define when a tuple <math>(\Delta,l)</math> is a ''proof in progress'' for <math>s</math>, with <math>\Delta</math> a DV constraint and <math>l\in E(V,F)_D^*</math>, recursively as follows:
# The tuple <math>(\emptyset,\epsilon)</math> is a proof in progress for <math>s</math>.
# If <math>(\Delta,(e_1,\ldots,e_m))</math> is a proof in progress and <math>e</math> is a hypothesis of <math>s</math>, then <math>(\Delta,(e_1,\ldots,e_m,[e]_D))</math> is a proof in progress.
# Let <math>s'\in S</math> and <math>(\Delta,(e_1,\ldots,e_m))</math> be a proof in progress such that <math>n:=NH(s')\leq m</math>. Assume there is a proper substitution map <math>u</math> such that <math>[H_1(s')]_D,\ldots,[H_n(s')]_D</math> are simultaneously unifiable with <math>e_{m-n+1},\ldots,e_m</math> through <math>u</math>. Assume furthermore that for all <math>(v_1,v_2)\in DV(s')</math> the symmetric closure of <math>A(\tilde{u}(v_1))\times A(\tilde{u}(v_2))</math> is a DV constraint and let <math>\Delta'</math> be the union of all these constraints. Then <math>(\Delta\cup\Delta',(e_1,\ldots,e_{m-n},[\tilde{u}(C(s'))]_D))</math> is a proof in progress.
# Nothing else is a proof in progress.

'''Explanation.''' In JHilbert, proofs are lists consisting of hypotheses, statements and expressions. From this list, the proof in progress is generated step by step starting from <math>(\emptyset,\epsilon)</math>. For list items which are hypotheses or statements, the proof in progress in generated as its definition suggests. Note that there may still be an ambiguity in the proper substitution map <math>u</math>. The variables for which the application of <math>u</math> to <math>C(s')</math> is ambiguous are precisely those apparent variables of the consequent of <math>s</math> which are not apparent in its hypotheses. To resolve these ambiguities, the JHilbert proof may also contain expressions.

'''Definition.''' Let <math>s</math> be a pending statement and <math>(\Delta,(e_1,\ldots,e_m))</math> be a proof in progress for <math>s</math>. Then <math>(\Delta,(e_1,\ldots,e_m))</math> is called a ''proof'' of <math>s</math> if <math>m=1</math>, <math>C(s)</math> and <math>e_1</math> are V-equivalent and <math>\Delta_W\subseteq DV(s)</math>, where <math>W=\bigcup\limits_{i=1}^{NH(s)}A(H_i(s))\cup (O(e_1)\setminus V_D)</math>.

'''Explanation.''' At the end of the proof, we would like the proof result (i.e., the only expression class in the proof in progress) to contain the consequent. However, due to definitions, dummy variables may be incurred. Therefore we demand only V-equivalence: the user is allowed to fill in the dummies with variables that are unrelated to <math>s</math>, as is ensured by the restrictions on [[w:domain of a function|domain]] and [[w:codomain|codomain]] of the proper substitution map <math>u</math> in V-equivalence. Furthermore, the required DV constraints <math>\Delta</math> amassed during proof development must be a subset of the DV constraints <math>s</math> promises to hold. Again, unrelated variables are stripped. This begs the question how soundness is ensured due to ignored DV constraints on these unrelated variables. The solution is to always consider these unrelated variables implicitly distinct. This is ensured by the injectivity of <math>u</math>. On the other hand, one might fear that this implicit constraint is too restrictive (i.e. it may destroy completeness of some normally complete systems). However, the only unrelated variables in the consequent are dummy variables, and each of these appears in at most one definition. One onus is left on the user: to match all these dummy variables uniquely, extra variables might have to be defined. In theory, the number of extra variables can grow arbitrarily large. In practice, however, one should not need more than a handful, so this is hardly a nuisance.

== First order logic ==

The material in this section follows <ref name="bilaniuk">{{sc|S. Bilaniuk}}, A Problem Course in Mathematical Logic</ref> very closely.

=== The first order language ===

'''Definition.''' <math>\sigma</math> is called a ''symbol'' of first order logic if and only if exactly one of the following conditions applies:
# <math>\sigma</math> is a ''parenthesis'', <math>(</math> or <math>)</math>.
# <math>\sigma</math> is a ''logical connective'', <math>\rightarrow</math> or <math>\neg</math>.
# <math>\sigma</math> is the ''quantifier'' <math>\forall</math>.
# <math>\sigma\in\mathfrak{V}</math> where <math>\mathfrak{V}</math> is a finite or countably infinite set of ''first order variables''.
# <math>\sigma</math> is the ''equality symbol'' <math>=</math>.
# <math>\sigma\in\mathfrak{C}</math> where <math>\mathfrak{C}</math> is a finite or countably infinite set of ''constants''.
# There is a <math>k\in\mathbb{Z}_{>0}</math> such that <math>\sigma\in\mathfrak{F}_k</math>, where <math>\mathfrak{F}_k</math> is a finite or countably infinite set of <math>k</math>-place ''function symbols''.
# There is a <math>k\in\mathbb{Z}_{>0}</math> such that <math>\sigma\in\mathfrak{R}_k</math>, where <math>\mathfrak{R}_k</math> is a finite or countably infinite set of <math>k</math>-place ''relation symbols''.
We denote the set of all symbols taken together by <math>\mathfrak{S}</math>.

Obviously, the definition of a symbol depends on what the sets <math>\mathfrak{V},\mathfrak{C},\{\mathfrak{F}_k\}_{k\in\mathbb{Z}_{>0}},\{\mathfrak{R}_k\}_{k\in\mathbb{Z}_{>0}}</math> are. We shall specifiy that at the end of this subsection.

'''Definition.''' We recursively define what a ''term'' is as follows:
# Each constant or variable symbol is a term.
# If <math>t_1,\ldots,t_n</math> are terms and <math>f\in\mathfrak{F}_n</math>, then the sequence <math>ft_1\cdots t_n</math> is a term.
# Nothing else is a term.

'''Lemma 26.''' If a sequence of symbols can be interpreted as a term, then this interpretation is unique.

{{sc|Proof.}} This follows from the uniqueness of Polish notation, given that the place count of the function symbols is known.

'''Definition.''' We recursively define what an ''atomic formula'' is as follows:
# If <math>t_1,\ldots,t_n</math> are terms and <math>r\in\mathfrak{R}_n</math>, then <math>rt_1\cdots t_n</math> is an atomic formula.
# If <math>t_1,t_2</math> are terms, then <math>=t_1t_2</math> is an atomic formula.
# Nothing else is an atomic formula.

'''Definition.''' We recursively define what a ''formula'' is as follows:
# Every atomic formula is a formula.
# If <math>p</math> is a formula, so is <math>(\neg p)</math>.
# If <math>p,q</math> are formulas, so is <math>(p\rightarrow q)</math>.
# If <math>p</math> is a formula and <math>v\in\mathfrak{V}</math>, then <math>\forall v p</math> is a formula.
# Nothing else is a formula.

'''Lemma 27.''' If a sequence of symbols can be interpreted as a formula, then this interpretation is unique.

{{sc|Proof.}} For atomic formulas and formulas involving the quantifier <math>\forall</math> this follows from uniqueness of Polish notation and lemma 26. For the other formulas this follows from the use of parentheses (which are used nowhere else).

(We're getting a little sloppy in the proofs of lemmata 26 and 27. Actually one would need induction over the number of symbols in a formula.)

'''Definition.''' Let <math>p</math> be a formula and <math>v\in\mathfrak{V}</math>. Then <math>v</math> ''occurs'' in <math>p</math> if <math>v</math> occurs in the string of symbols making up <math>p</math>.

'''Definition.''' Let <math>p</math> be a formula and <math>v\in\mathfrak{V}</math>. We define when <math>v</math> ''occurs free'' in <math>p</math> recursively as follows:
# If <math>p</math> is atomic, then <math>v</math> occurs free in <math>p</math> if and only if <math>v</math> occurs in <math>p</math>.
# If there is a formula <math>q</math> such that <math>p</math> has the form <math>(\neg q)</math>, then <math>v</math> occurs free in <math>p</math> if and only if <math>v</math> occurs free in <math>q</math>.
# If there are formulas <math>q_1,q_2</math> such that <math>p</math> has the form <math>(q_1\rightarrow q_2)</math>, then <math>v</math> occurs free in <math>p</math> if and only if <math>v</math> occurs free in <math>q_1</math> or <math>q_2</math>.
# If there is a <math>w\in\mathfrak{V}</math> and a formula <math>q</math> such that <math>p</math> has the form <math>\forall w q</math>, then <math>v</math> occurs free in <math>p</math> if and only if <math>v</math> and <math>w</math> are distinct and <math>v</math> occurs free in <math>q</math>.

'''Definition.''' Our ''language'' <math>\mathcal{L}:=(\mathfrak{V},\mathfrak{C},\{\mathfrak{F}_k\}_{k\in\mathbb{Z}_{>0}},\{\mathfrak{R}_k\}_{k\in\mathbb{Z}_{>0}})</math> will be a language where <math>\mathfrak{V}</math> is countably infinite, all other sets are finite, and <math>\mathfrak{F}_k=\mathfrak{R}_k=\emptyset</math> for <math>k\gg 0</math>. We must ensure that all symbols are unique, so we denote the elements as follows:
* <math>\mathfrak{V}=\{v_1,v_2,v_3,\ldots\}</math>,
* <math>\mathfrak{C}=\{c_1,c_2,\ldots,c_{N_C}\}</math>,
* <math>\mathfrak{F}_k=\{f^k_1,f^k_2,\ldots,f^k_{N^k_F}\}</math> for all <math>k\in\mathbb{Z}_{>0}</math>,
* <math>\mathfrak{R}_k=\{r^k_1,r^k_2,\ldots,r^k_{N^k_R}\}</math> for all <math>k\in\mathbb{Z}_{>0}</math>.

Most first order languages can be construed as a case of <math>\mathcal{L}</math>. For a specific (finite) situation this is always possible. Most practical languages have very few relation symbols. For example, there are axiomatisations of set theory which need only <math>\in</math>.

=== Deductions ===

'''Definition.''' Let <math>t</math> be a term and <math>v\in\mathfrak{V}</math>. Then <math>v</math> ''occurs'' in <math>t</math> if <math>v</math> occurs in the string of symbols making up <math>t</math>.

'''Definition.''' Let <math>p</math> be a formula, <math>v\in\mathfrak{V}</math> and <math>t</math> be a term. Then we define when <math>t</math> is ''substitutable'' for <math>v</math> in <math>p</math> recursively as follows:
# If <math>p</math> is atomic, then <math>t</math> is substitutable for <math>v</math> in <math>p</math>.
# If there is a formula <math>q</math> such that <math>p</math> has the form <math>(\neg q)</math>, then <math>t</math> is substitutable for <math>v</math> in <math>p</math> if and only if <math>t</math> is substitutable for <math>v</math> in <math>q</math>.
# If there are formulas <math>q_1,q_2</math> such that <math>p</math> has the form <math>(q_1\rightarrow q_2)</math>, then <math>t</math> is substitutable for <math>v</math> in <math>p</math> if and only if <math>t</math> is substitutable for <math>v</math> in both <math>q_1</math> and <math>q_2</math>.
# If there is a <math>w\in\mathfrak{V}</math> and a formula <math>q</math> such that <math>p</math> has the form <math>\forall w q</math>, then <math>t</math> is substitutable for <math>v</math> in <math>p</math> if and only if either <math>v</math> does not occur free in <math>p</math> or if <math>w</math> does not occur in <math>t</math> and <math>t</math> is substitutable for <math>v</math> in <math>q</math>.

'''Definition.''' Let <math>p</math> be a formula, <math>v\in\mathfrak{V}</math> and <math>t</math> be a term which is substitutable for <math>v</math> in <math>p</math>. Then we define the ''substitution'' of <math>v</math> for <math>t</math> in <math>p</math>, denoted by <math>p_t^v</math>, recursively as follows:
# If <math>p</math> is atomic, then <math>p_t^v</math> is <math>p</math> with all occurrences of <math>v</math> replaced with <math>t</math>.
# If there is a formula <math>q</math> such that <math>p</math> has the form <math>(\neg q)</math>, then <math>p_t^v</math> is <math>(\neg q_t^v)</math>.
# If there are formulas <math>q_1,q_2</math> such that <math>p</math> has the form <math>(q_1\rightarrow q_2)</math>, then <math>p_t^v</math> is <math>({q_1}_t^v\rightarrow{q_2}_t^v)</math>.
# If there is a <math>w\in\mathfrak{V}</math> and a formula <math>q</math> such that <math>p</math> has the form <math>\forall w q</math>, then <math>p_t^v</math> is <math>\forall w q_t^v</math> if <math>v</math> and <math>w</math> are distinct, and simply <math>p</math> if they are not.

'''Definition.''' Let <math>p</math> be a formula. We define when <math>p</math> is ''derivable'' recursively as follows.
:'''A1.''' If there are formulas <math>q_1,q_2</math> such that <math>p</math> has the form <math>(q_1\rightarrow(q_2\rightarrow q_1))</math>, then <math>p</math> is derivable.
:'''A2.''' If there are formulas <math>q_1,q_2,q_3</math> such that <math>p</math> has the form <math>((q_1\rightarrow(q_2\rightarrow q_3))\rightarrow((q_1\rightarrow q_2)\rightarrow(q_1\rightarrow q_3)))</math>, then <math>p</math> is derivable.
:'''A3.''' If there are formulas <math>q_1,q_2</math> such that <math>p</math> has the form <math>(((\neg q_2)\rightarrow(\neg q_1))\rightarrow(((\neg q_2)\rightarrow q_1)\rightarrow q_2))</math>, then <math>p</math> is derivable.
:'''A4.''' If there is a <math>v\in\mathfrak{V}</math>, a formula <math>q</math> and a term <math>t</math> such that <math>t</math> is substitutable for <math>v</math> in <math>q</math>, such that <math>p</math> has the form <math>(\forall v q\rightarrow q_t^v)</math>, then <math>p</math> is derivable.
:'''A5.''' If there is a <math>v\in\mathfrak{V}</math> and formulas <math>q_1,q_2</math> such that <math>p</math> has the form <math>(\forall v(q_1\rightarrow q_2)\rightarrow(\forall vq_1\rightarrow\forall vq_2))</math>, then <math>p</math> is derivable.
:'''A6.''' If there is a formula <math>q</math> and a <math>v\in\mathfrak{V}</math> which does not occur free in <math>q</math> such that <math>p</math> has the form <math>(q\rightarrow\forall v q)</math>, then <math>p</math> is derivable.
:'''A7.''' If there is a <math>v\in\mathfrak{V}</math> such that <math>p</math> has the form <math>=vv</math>, then <math>p</math> is derivable.
:'''A8.''' If there are <math>v,w\in\mathfrak{V}</math> and atomic formulas <math>q_1,q_2</math> which are identical symbol for symbol except that for each occurrence of <math>v</math> in <math>q_1</math>, <math>q_2</math> may have either <math>v</math> or <math>w</math> at that location, such that <math>p</math> has the form <math>(=vw\rightarrow(q_1\rightarrow q_2))</math>, then <math>p</math> is derivable.
:'''MP.''' If there is a derivable formula <math>q</math> such that <math>(q\rightarrow p)</math> is derivable, then <math>p</math> is derivable.
:'''X.''' Nothing else is derivable.
We denote the set of derivable formulas by <math>\mathfrak{D}</math>.

=== Captured occurrences of variables ===

'''Definition.''' Let <math>n\in\mathbb{Z}_{>0}</math>, <math>p</math> be a formula which consists of at least <math>n</math> symbols and suppose the <math>n</math>-th symbol of <math>p</math> is the variable <math>v\in\mathfrak{V}</math>. In other words, we have a specific occurrence of <math>v</math> in <math>p</math>, denoted by <math>o(v,p,n)</math>. Then we define when <math>o(v,p,n)</math> is ''uncaptured'' recursively as follows:
# If <math>p</math> is atomic, then <math>o(v,p,n)</math> is uncaptured.
# If there is a formula <math>q</math> such that <math>p</math> has the form <math>(\neg q)</math>, then <math>o(v,p,n)</math> is uncaptured if and only if that occurrence of <math>v</math> in <math>q</math> is uncaptured.
# If there are formulas <math>q_1,q_2</math> such that <math>p</math> has the form <math>(q_1\rightarrow q_2)</math>, then <math>o(v,p,n)</math> is uncaptured if and only if either that occurence takes place in <math>q_1</math> and is uncaptured there, or it takes place in <math>q_2</math> and is uncaptured there.
# If there is a <math>w\in\mathfrak{V}</math> and a formula <math>q</math> such that <math>p</math> has the form <math>\forall w q</math>, then <math>o(v,p,n)</math> is uncaptured if and only if <math>v</math> and <math>w</math> are distinct (in particular, <math>n>2</math>) and that occurrence of <math>v</math> in <math>q</math> is uncaptured.
If <math>o(v,p,n)</math> is not uncaptured, it is ''captured''.

'''Explanation.''' In programmer lingo, an occurrence of a variable <math>v</math> being captured would mean that <math>v</math> lies in the [[w:scope (programming)|scope]] of a quantifier of the form <math>\forall v\ldots</math>.

== Implementation of first order logic in JHilbert ==

In this section we will give a description of an implementation of <math>\mathcal{L}</math>. Of course, the implementation we describe will depend on <math>\mathcal{L}</math> and possibly on user definitions. The implementation will largely be concerned with a JHilbert ''interface''. Later, when we check the soundness of the implementation, we will be concerned with an arbitrary ''proof module'' which imports the interface.

First, our interface will need the three kinds
 kind (variable)
 kind (term)
 kind (formula)
to mimic first order variables, terms and formulas as JHilbert expressions (see below). Note that we shall not need separate kinds for constants or atomic formulas.

The set <math>\mathfrak{V}</math> is countably infinite. However, variables in JHilbert are local to a module. A module only has finite length, so only a finite number of variables is required in a single module. (This is a slightly dangerous statement as the length of the module depends on the number of variables being declared. What we mean is that essentially, we write the module without <code>var</code> commands first and then add <code>var</code> commands as needed and nothing more.) Hence we shall introduce a sufficient number of variables for first order variables and terms, and since we're at it, also for formulas:
 var (variable v1 v2 v3 &hellip; )
 var (term V1 V2 V3 &hellip; )
 var (formula p1 p2 p3 &hellip; )
(replace "&hellip;" with sufficiently many variable names).

In order to express that first order variables are first order terms, we introduce the following functor:
 term (term (tv variable))
The <code>tv</code> functor will make terms of variables in JHilbert expressions.

We implement the constants <math>c_1,\ldots,c_{N_C}</math> as nullary functors:
 term (term (c1))
 term (term (c2))
 &hellip;
 term (term (c<math>_{N_C}</math>))
(fill in the necessary lines for "&hellip;" and replace <math>_{N_C}</math> with the appropriate representation of <math>N_C</math> in the [[w:decimal|decimal]] system).

For each <math>k\in\mathbb{Z}_{>0}</math>, we implement the function symbols <math>f^k_1,\ldots,f^k_{N^k_F}</math> by <math>k</math>-ary functors
 term (term (f_<math>k</math>_1 term &hellip; term))
 &hellip;
 term (term (f_<math>k</math>_<math>_{N^k_F}</math> term &hellip; term))
(fill in the necessary lines, replace <math>k</math> and <math>_{N^k_F}</math> with the proper decimal representations and make the place count of the functors <math>k</math>).

For each <math>k\in\mathbb{Z}_{>0}</math>, we implement the relation symbols <math>r^k_1,\ldots,r^k_{N^k_F}</math> by <math>k</math>-ary functors
 term (formula (r_<math>k</math>_1 term &hellip; term))
 &hellip;
 term (forumla (r_<math>k</math>_<math>_{N^k_R}</math> term &hellip; term))
(fill in the necessary lines, replace <math>k</math> and <math>_{N^k_R}</math> with the proper decimal representations and make the place count of the functors <math>k</math>).
The equality symbol can be treated as a binary relation symbol:
 term (formula (= term term))

Implementation of non-atomic formulas is straightforward:
 term (formula (¬ formula))
 term (formula (→ formula formula))
 term (formula (∀ variable formula))
We also define some derived connectives:
 def ((∧ p1 p2) (¬ (p1 → (¬ p2))))
 def ((∨ p1 p2) ((¬ p1) → p2))
 def ((↔ p1 p2) ((p1 → p2) ∧ (p2 → p1)))

Next, we implement substitutions in terms. JHilbert already has a built-in substitution mechanism. We need additional substitution axioms only for replacing <code>(tv ''variable'')</code> terms with generic terms. First, we define a term substitution functor:
 term (term (tsubst term variable term))
(meaning each occurrence of <code>''variable''</code> in the first <code>''term''</code> is replaced by the second <code>''term''</code>. For <code>tv</code>-free terms, it has no effect:
 stmt (tsubstid ((v1 V1)) () (= (tsubst V1 v1 V2) V1))
We need a generic variable-to-term substitution:
 stmt (tvsubst () () (= (tsubst (tv v1) v1 V1) V1))
Finally, we need a substitution axiom for each function symbol <math>f^k_m</math>:
 stmt (tsubst_''k''_''m'' () () (=
  (tsubst (f_''k''_''m'' V1 &hellip; V''m'') v1 V''m+1'')
  (f_''k''_''m'' (tsubst V1 v1 V''m+1'') &hellip; (tsubst V''m'' v1 V''m+1''))
 ))
(fill in the JHilbert expressions and replace the italic arithmetic expressions by their proper decimal representation).

Now that we have substitutions in terms, we should also define them for formulas via a functor
 term (formula (fsubst formula variable term))
Note that the meaning of <code>fsubst</code> here is:
:'''If''' <code>''term''</code> is substitutable for <code>''variable''</code> in <code>''formula''</code> then <code>(fsubst ''formula'' ''variable'' ''term'')</code> is that substitution.
In other words, we must make sure that the axioms involving <code>fsubst</code> are applicable only in the case of substitutability. For a relation symbol <math>r^k_m</math> we need an axiom similar to the case of function symbols:
 stmt (fsubst_''k''_''m'' () () (
  (fsubst (r_''k''_''m'' V1 &hellip; V''m'') v1 V''m+1'') ↔
  (r_''k''_''m'' (tsubst V1 v1 V''m+1'') &hellip; (tsubst V''m'' v1 V''m+1''))
 ))
Likewise for the equality symbol:
 stmt (fsubsteq () () ((fsubst (= V1 V2) v1 V3) ↔ (= (tsubst V1 v1 V3) (tsubst V2 v1 V3))))
We also need a straightforward substitution axiom each for negation and implication:
 stmt (fsubstneg () () ((fsubst (¬ p1) v1 V1) ↔ (¬ (fsubst p1 v1 V1))))
 stmt (fsubstimp () () ((fsubst (p1 → p2) v1 V1) ↔ ((fsubst p1 v1 V1) → (fsubst p2 v1 V1))
For formulas involving the quantifier we must distinguish between whether the substituted variable is equal to the quantified variable or not.
 stmt (fsubstalleq () () ((fsubst (∀ v1 p1) v1 V1) ↔ (∀ v1 p1)))
 stmt (fsubstallneq ((v1 v2)) () ((fsubst (∀ v1 p1) v2 V1) ↔ (∀ v1 (fsubst p1 v2 V1))))

== References ==

<references />