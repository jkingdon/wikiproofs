{{header
 | title    = Definition soundness of first-order logic in JHilbert
 | subtitle = 
 | left     = 
 | right    = 
 | shortcut = 
 | notes    = Attempt at a formal proof of soundness of first-order logic in JHilbert.
}}

== JHilbert ==

=== Names ===

'''Definition.''' <math>\Sigma</math> is a [[w:finite set|finite]], [[w:empty set|non-empty]] [[w:set (mathematics)|set]], the ''characters''.

'''Definition.''' <math>N:=\Sigma^*\setminus\{\epsilon\}</math>, that is, the set of all non-empty, finite [[w:sequence|sequence]]s of characters is the set of ''names''.

'''Lemma 1.''' The set of names <math>N</math> is [[w:countably infinite|countably infinite]].

{{sc|Proof.}} <math>N</math> is infinite because <math>\Sigma\neq\emptyset</math>, and countable because <math>\Sigma</math> is finite.

=== Kinds ===

'''Definition.''' The ''kinds'' are a [[w:tuple|tuple]] <math>(K,\sim)</math> where <math>K\subseteq N</math> is finite and <math>\sim</math> is an [[w:equivalence relation|equivalence relation]] on <math>K</math>. We denote the set <math>K/\sim</math> of all [[w:equivalence class|equivalence class]]es by <math>\mathcal{K}</math>.

Where no confusion is possible, we shall not distinguish between kinds and equivalence classes of kinds.

'''Explanation.''' <math>K</math> and <math>\sim</math> are user-defined in JHilbert through the <code>kind</code> and <code>kindbind</code> commands. The <code>kind</code> command adds a new name to <math>K</math> which initially is equivalent only to itself. The <code>kindbind</code> command adds a relation between two kinds in <math>K</math> to <math>\sim</math> (possibly after adding a new name to <math>K</math>) and completes <math>\sim</math> by [[w:reflexive closure|reflexive]], [[w:symmetric closure|symmetric]] and [[w:transitive closure|transitive]] [[w:closure (mathematics)|closure]].

=== Variables ===

'''Definition.''' A tuple <math>(n,k)</math> with <math>n\in N</math> and <math>k\in\mathcal{K}</math> is a ''variable''. For each variable <math>v=(n,k)</math> we denote the [[w:projection (set theory)|projection]] <math>(n,k)\mapsto n</math>, the ''name of <math>v</math>'', by <math>N(v)</math>, and the projection <math>(n,k)\mapsto k</math>, the ''kind of <math>v</math>'', by <math>K(v)</math>.

'''Definition.''' A finite set <math>V</math> is called a ''permissible set of variables'' if all elements of <math>V</math> are variables, and the [[w:restriction (mathematics)|restriction]] of the name projection <math>N</math> to <math>V</math> is [[w:injective|injective]].

'''Lemma 2.''' Let <math>V</math> be a permissible set of variables. Then any <math>W\subseteq V</math> is also a permissible set of variables.

{{sc|Proof.}} <math>W</math> is finite since <math>V</math> is finite. <math>W</math> contains only variables since <math>W</math> is contained in <math>V</math>. Finally, the restriction of an injective function remains injective.

'''Theorem 1.''' Let <math>V</math> be a permissible set of variables. Then for any <math>k\in\mathcal{K}</math> there is a <math>n\in N</math> such that <math>(n,k)\notin V</math> and <math>V':=V\cup\{(n,k)\}</math> is a permissible set of variables.

{{sc|Proof.}} Since <math>V</math> is finite, the image <math>N(V)</math> is finite as well. Now, <math>N</math> is infinite by Lemma 1. Therefore, there exists an <math>n\in N\setminus N(V)</math>. Since <math>n\notin (\left.N\right|_V)^{-1}(N)</math>, <math>(n,k)\notin V</math>. <math>V'</math> is finite because <math>V</math> and the singleton <math>\{(n,k)\}</math> are finite, and <math>(n,k)</math> is clearly a variable. Again, since <math>n\notin (\left.N\right|_V)^{-1}(N)</math>, <math>N((n,k))\neq N(v)</math> for all <math>v\in V</math>. Therefore, the name projection is injective on <math>V'</math>.

'''Definition.''' The ''variables'' are a permissible set of variables <math>V</math>. It is [[w:partition of a set|partitioned]] into three subsets, the ''named variables'' <math>V_N</math>, the ''unnamed variables'' <math>V_U</math> and the ''dummy variables'' <math>V_D</math>. By Lemma 2, these subsets are also permissible sets of variables.

'''Explanation.''' The named variables <math>V_N</math> are user-defined in JHilbert through the <code>var</code> command. Unnamed variables and dummy variables are automatically introduced as explained later. Since the empty set is a permissible set of variables, Theorem 1 ensures that such automatic introduction of new variables is always possible. In fact, JHilbert cheats a little by extending <math>\Sigma</math> for this purpose, so the namespace for user-defined variables doesn't become polluted.

=== Functors ===

'''Definition.''' A tuple <math>(n,k,l)</math> with <math>n\in N</math>, <math>k\in\mathcal{K}</math> and <math>l\in\mathcal{K}^*</math> is a ''functor''. For each functor <math>f=(n,k,l)</math>, we denote the projection <math>(n,k,l)\mapsto n</math>, the ''name of <math>f</math>'', by <math>N(f)</math>, and the projection <math>(n,k,l)\mapsto k</math>, the ''kind of <math>f</math>'', by <math>K(f)</math>. Furthermore, we denote the function <math>(n,k,l)\mapsto|l|</math>, where <math>|l|</math> is the length of the sequence <math>l</math>, the ''place count of <math>f</math>'', by <math>PC(f)</math>. For each <math>i\in\mathbb{N}</math>, <math>1\leq i\leq PC(f)</math>, we denote by <math>IK_i(f)</math> the mapping of <math>(n,k,l)</math> to the <math>i</math>-th projection of <math>l</math>. We call <math>IK_i(f)</math> the ''<math>i</math>-th input kind of <math>f</math>.''

'''Definition.''' A finite set <math>F</math> is called a ''permissible set of functors'' if all elements of <math>F</math> are functors and the restriction of the name projection <math>N</math> to <math>F</math> is injective.

'''Lemma 3.''' Let <math>F</math> be a permissible set of functors. Then any <math>G\subseteq F</math> is also a permissible set of functors.

{{sc|Proof.}} The proof is similar to the proof of Lemma 2.

'''Definition.''' The ''functors'' are a permissible set of functors <math>F</math>.

=== Term functors ===

'''Definition.''' The ''term functors'' are a set <math>F_T\subseteq F</math>. By Lemma 3, term functors are a permissible set of functors.

'''Explanation.''' Term functors are user-defined in JHilbert through the <code>term</code> command. However, they are not the only functors as definitions (see below) give rise to further functors.

=== Expressions ===

'''Definition.''' We define when some element <math>e</math> is an ''expression'', and what the ''kind of <math>e</math>'', <math>K(e)</math>, is, [[w:recursive definition|recursively]] as follows:
# If <math>e\in V</math> then <math>e</math> is an expression. (In this case, <math>K(e)</math> is defined by the definition of the kind of a variable.)
# If <math>e=(f,s)</math> where <math>f\in F</math> and <math>s</math> is a finite sequence of expressions such that <math>PC(f)=|s|</math> and for <math>i=1,\ldots,|s|</math> the <math>i</math>-th element of <math>s</math>, <math>s_i</math>, fulfils the equation <math>IK_i(f)=K(s_i)</math>, then <math>e</math> is an expression.
# Nothing else is an expression.
# If <math>e=(f,s)</math> is an expression, then <math>K(e)=K(f)</math>.
We denote the set of all expressions by <math>E(V,F)</math>.

'''Lemma 4.''' The set <math>E(V,F)</math> is either finite or countably infinite.

{{sc|Proof.}} By using [[w:polish notation|polish notation]] we may consider <math>E(V,F)</math> a subset of <math>(V\cup F)^*</math>. Since both <math>V</math> and <math>F</math> are finite, that set is finite or countably infinite. Hence <math>E(V,F)</math> is finite or countably infinite.

'''Definition.''' Let <math>e\in E(V,F)</math>. Then we define the ''length of <math>e</math>'', <math>|e|</math> recursively as follows:
# If <math>e\in V</math> then <math>|e|=1</math>.
# If <math>e=(f,s)</math> then <math>|e|</math> is the sum of the lengths of the expressions in <math>s</math>, plus one.

'''Lemma 5.''' Let <math>e\in E(V,F)</math>. Then <math>|e|=1</math> if and only if either <math>e\in V</math> or <math>e=(f,s)</math> with <math>PC(f)=0</math> and hence <math>s=\epsilon</math>.

{{sc|Proof.}} If <math>e\in V</math> or <math>e=(f,s)</math> with the stated properties then clearly <math>|e|=1</math>. Now assume <math>e=(f,s)</math> with <math>PC(f)\neq 0</math>. But then surely <math>|e|>1</math> since all expressions in <math>s</math> have length at least one.

'''Definition.''' Let <math>e_1,e_2\in E(V,F)</math>. Then we define when <math>e_2</math> is a ''subexpression'' of <math>e_1</math> recursively as follows.
# If <math>e_1\in V</math> then <math>e_2</math> is a subexpression of <math>e_1</math> if and only if <math>e_1=e_2</math>.
# If <math>e_1=(f,s)</math> then <math>e_2</math> is a subexpression of <math>e_1</math> if and only if either <math>e_1=e_2</math> or <math>e_2</math> is a subexpression of one of the expressions in <math>s</math>.

'''Lemma 6.''' Let <math>e_1\in E(V,F)</math> and let <math>e_2</math> be a subexpression of <math>e_1</math>. Then <math>|e_2|\leq|e_1|</math> and equality holds if and only if <math>e_1=e_2</math>.

{{sc|Proof.}} This follows from the strict [[w:monotonicity|monotonicity]] of the addition of [[w:positive integer|positive integer]]s.

'''Definition.''' Let <math>e\in E(V,F)</math> and <math>f\in F</math>. We define when <math>f</math> is ''apparent'' in <math>e</math> recursively as follows:
# If <math>e=(f',\epsilon)</math> then <math>f</math> is apparent in <math>e</math> if and only if <math>f=f'</math>.
# If <math>e=(f',s)</math> then <math>f</math> is apparent in <math>e</math> if and only if either <math>f=f'</math> or <math>f</math> is apparent in at least one of the expressions in <math>s</math>.
# In no other case is <math>f</math> apparent in <math>e</math>.

'''Definition.''' Let <math>e\in E(V,F)</math> and <math>v\in V</math>. We define when <math>v</math> is ''apparent'' in <math>e</math> recursively as follows:
# If <math>e\in V</math> then <math>v</math> is apparent in <math>e</math> if and only if <math>e=v</math>.
# If <math>e=(f,s)</math> then <math>v</math> is apparent in <math>e</math> if and only if it is apparent in at least one of the expressions in <math>s</math>.
We denote the set of apparent variables of <math>e</math> by <math>A(e)</math>.

'''Definition.''' Let <math>e\in E(V,F)</math> and let <math>v_1,v_2\in A(e)</math>. We define when <math>v_1\leq_e v_2</math> recursively as follows:
# If <math>e\in V</math> then <math>v_1\leq_e v_2</math>.
# If <math>e=(f,s)</math> and there is an expression <math>e_1</math> in <math>s</math> such that
#:* <math>v_1\in A(e_1)</math>,
#:* <math>v_2\notin A(e')</math> for all expressions <math>e'</math> before <math>e_1</math> in <math>s</math>,
#:* <math>v_2\notin A(e_1)</math> or <math>v_1\leq_{e_1} v_2</math>,
#:then <math>v_1\leq_e v_2</math>.
# <math>v_1\leq_e v_2</math> in no other case.

'''Lemma 7.''' Let <math>e\in E(V,F)</math>. Then <math>(A(e),\leq_e)</math> is a [[w:total order|totally ordered]] set.

{{sc|Proof.}} We prove this by [[w:mathematical induction|induction]] over <math>|e|</math>. First, if <math>|e|=1</math> then by Lemma 5 either <math>A(e)=\emptyset</math> in which case there is nothing to prove, or <math>A(e)</math> contains only one element. Since <math>\leq_e</math> is obviously reflexive, [[w:antisymmetric relation|antisymmetry]], transitivity and [[w:total relation|totality]] follow in this case. Now assume <math>|e|>1</math> (that is <math>e=(f,s)</math>) and let the statement be proven for all expressions of length smaller than <math>|e|</math>. Now let <math>v_1,v_2\in A(e)</math> and assume <math>v_1\not\leq_e v_2</math>. Since <math>v_2\in A(e)</math>, there is an expression <math>e_1</math> in <math>s</math> such that <math>v_2\in A(e_1)</math>. Since the [[w:natural number|natural number]]s are [[w:well-order|well-order]]ed, we may assume <math>e_1</math> to be the leftmost such expression in <math>s</math>. Now, if there was an expression <math>e'</math> in <math>s</math> before <math>e_1</math>, then <math>v_1\leq_e v_2</math>, which we have excluded. Since <math>v_1\in A(e)</math>, either <math>v_1\in A(e')</math> for some <math>e'</math> after <math>e_1</math> in <math>s</math>, in which case <math>v_2\leq_e v_1</math> follows, or <math>v_1\in A(e_1)</math>, which case again <math>v_2\leq_e v_1</math> since by induction hypothesis <math>\leq_{e_1}</math> is total. This establishes the totality of <math>\leq_e</math>. Next, assume both <math>v_1\leq_e v_2</math> and <math>v_2\leq_e v_1</math>. Then by similar reasoning as above, <math>v_1,v_2\in A(e_1)</math> and antisymmetry follows since <math>\leq_{e_1}</math> is antisymmetric by induction hypothesis, so <math>\leq_e</math> is antisymmetric. Finally, let <math>v_3\in A(e)</math> and assume <math>v_1\leq_e v_2</math> and <math>v_2\leq _e v_3</math>. As above, let <math>e_1,e_2,e_3</math> the respective leftmost expressions in <math>s</math> such that <math>v_i\in A(e_i)</math>, <math>i=1,2,3</math>. Since <math>v_1\leq_e v_2</math>, <math>e_2</math> cannot come before <math>e_1</math> in <math>s</math>. Similarly, <math>e_3</math> cannot come before <math>e_2</math> in <math>s</math>. Therefore, <math>e_3</math> cannot come before <math>e_1</math> in <math>s</math>. If <math>e_1</math> comes before <math>e_3</math> then <math>v_1\leq_e v_3</math>. Otherwise <math>e_1=e_3</math> and <math>v_1\leq_e v_3</math> follows since <math>\leq_{e_1}=\leq_{e_3}</math> is transitive by induction hypothesis. This establishes the transitivity of <math>\leq_e</math> and thus finishes the proof.

'''Definition.''' Let <math>W\subseteq V</math> and <math>u\colon W\to E(V,F)</math> a map such that all <math>w\in W</math> fulfil the equation <math>K(w)=K(u(w))</math>. Then <math>u</math> is called a ''proper substitution map''. We also define the ''extension'' <math>\tilde{u}</math> of <math>u</math> on <math>E(V,F)</math> recursively by
# <math>\tilde{u}(w)=u(w)</math> for all <math>w\in W</math>,
# <math>\tilde{u}(v)=v</math> for all <math>v\in V\setminus W</math>,
# <math>\tilde{u}((f,(e_1,\ldots,e_n)))=(f,(\tilde{u}(e_1),\ldots,\tilde{u}(e_2)))</math> for all <math>(f,(e_1,\ldots,e_n))\in E(V,F)\setminus V</math>.

'''Lemma 8.''' Let <math>u\colon W\to E(V,F)</math> be a proper substitution map. Then the image of the extension <math>\tilde{u}(E(V,F))\subseteq E(V,F)</math> and for all <math>e\in E(V,F)</math> the equation <math>K(e)=K(\tilde{u}(e))</math> holds.

{{sc|Proof.}} Let <math>e\in E(V,F)</math>. We have to show that <math>\tilde{u}(e)\in E(V,F)</math> and <math>K(e)=K(\tilde{u}(e))</math>. We prove this by induction over <math>|e|</math>. First, assume <math>|e|=1</math>. Then either <math>e=(f,\epsilon)</math> in which case <math>\tilde{u}(e)=e</math>, or <math>e\in V</math>. If <math>e\in V\setminus W</math> then again <math>\tilde{u}(e)=e</math>. If <math>e\in W</math> then <math>\tilde{u}(e)=u(e)\in E(V,F)</math> and <math>K(\tilde{u}(e))=K(u(e))=K(e)</math> by the definition of a proper substitution map. This proves the statement for <math>|e|=1</math>. Now assume the statement proven for all expressions of length smaller than <math>|e|>1</math>. Then <math>e=(f,(e_1,\ldots,e_n))</math>. By the induction hypothesis, <math>(\tilde{u}(e_1),\ldots,\tilde{u}(e_n))</math> is a sequence of expressions. Its length is equal to the length of <math>(e_1,\ldots,e_n)</math>. The induction hypothesis also implies that for <math>i=1,\ldots,n</math> we have <math>IK_i(f)=K(e_i)=K(\tilde{u}(e_i))</math>. Therefore <math>\tilde{u}(e)\in E(V,F)</math>. Since <math>K(\tilde{u}(e))=K(f)</math> and <math>K(e)=K(f)</math>, the statement is proven.

'''Lemma 9.''' Let <math>u\colon W\to E(V,F)</math> be a proper substitution map and <math>W'\subseteq W</math>. Then the restriction <math>\left.u\right|_{W'}</math> is also a proper substitution map and <math>\tilde{u}(e)=(\left.u\right|_{W'})^\sim(e)</math> for all <math>e\in E(V,K)</math> with <math>A(e)\subseteq W'</math>.

{{sc|Proof.}} That <math>\left.u\right|_{W'}</math> is also a proper substitution map is clear from the definition. Now let <math>e\in E(V,F)</math> such that <math>A(e)\subseteq W'</math>. We prove the remainder of the statement by induction over <math>|e|</math>. First, assume <math>|e|=1</math>. Then either <math>e=(f,\epsilon)</math> in which case the statement is clear, or <math>e\in V</math>, in which case it follows by <math>e\in W'</math>. Now, for the case <math>|e|>1</math> we have <math>e=(f,(e_1,\ldots,e_n))</math> and since clearly <math>A(e_i)\subseteq A(e)</math> for <math>i=1,\ldots,n</math>, the statement follows in this case also from the induction hypothesis.

'''Definition.''' Let <math>e_1,e_2\in E(V,F)</math>. Then <math>e_2</math> ''arises from <math>e_1</math> by proper substitution'' if there is a proper substitution map <math>u\colon A(e_1)\to E(V,F)</math> such that <math>\tilde{u}(e_1)=e_2</math>.

'''Lemma 10.''' Let <math>e_1=(f_1,(e_{11},\ldots,e_{1n}))</math> and <math>e_2=(f_2,(e_{21},\ldots,e_{2m}))</math> be expressions. Assume furthermore that <math>e_2</math> arises from <math>e_1</math> by proper substitution. Then <math>f_1=f_2</math>, <math>n=m</math> and if <math>u\colon A(e_1)\to E(V,F)</math> is a proper substitution map such that <math>\tilde{u}(e_1)=e_2</math> then <math>(\left. u\right|_{A(e_{1i})})^\sim(e_{1i})=e_{2i}</math> for all <math>i=1,\ldots,n</math>.

{{sc|Proof.}} That <math>f_1=f_2</math> and <math>n=m</math> is clear. The remainder of the statement follows from the definition of a proper substitution map and Lemma 9.

'''Lemma 11.''' Let <math>e_1,e_2\in E(V,F)</math> be such that <math>e_2</math> arises from <math>e_1</math> by proper substitution. Then the proper substitution map <math>u\colon A(e_1)\to E(V,F)</math> such that <math>\tilde{u}(e_1)=e_2</math> is [[w:unique|unique]].

{{sc|Proof.}} Assume there are two such maps <math>u_1,u_2\colon A(e_1)\to E(V,F)</math> which are different. Then there is a <math>v\in A(e_1)</math> such that <math>u_1(v)\neq u_2(v)</math>. We proceed with an induction over <math>|e_1|</math>. If <math>|e_1|=1</math>, then either <math>e_1=(f,\epsilon)</math> in which case <math>A(e_1)=\emptyset</math>, so <math>u_1,u_2</math> cannot be distinct, or <math>e_1\in V</math>. In this case, <math>e_1=v</math> since <math>v</math> is apparent in <math>e_1</math>. But then <math>u_1(e_1)\neq u_2(e_1)</math>, which is [[w:reductio ad absurdum|absurd]]. Now assume the statement proven for all expressions of length smaller than <math>|e_1|>1</math>. Then <math>e_1=(f,(e_{11},\ldots,e_{1n}))</math>, so there must be a positive integer <math>1\leq i\leq n</math> such that <math>\tilde{u}_1(e_{1i})\neq\tilde{u}_2(e_{1i})</math> since <math>v</math> must be apparent in one of the <math>e_{1i}</math>. But this contradicts the induction hypothesis in combination with Lemma 10.

'''Definition.''' Let <math>(f,s)</math> be an expression. Then <math>f</math> is called the ''head functor'' of <math>(f,s)</math>.

=== Definitions ===

'''Definition.''' We define the ''definition functors'' as <math>F_D:=F\setminus F_T</math>.

'''Definition.''' Let <math>l\in V^*</math>. Write <math>l=(v_1,\ldots,v_n)</math>. Then we set <math>K(l):=(K(v_1),\ldots,K(v_n))\in\mathcal{K}^*</math>.

'''Definition.''' Let <math>d=(n,l,e)</math> with <math>n\in N</math>, <math>l\in V_U^*</math> and <math>e\in E(V,K)</math> such that <math>F(d):=(n,K(e),K(l))\in F_D</math>. Assume furthermore that for all <math>v\in A(e)</math> either <math>v</math> occurs in <math>l</math> or <math>v\in V_D</math>. Then <math>d</math> is called a ''definition-like tuple''.

'''Definition.''' Let <math>D</math> be a set of definition-like tuples such that <math>F\colon D\to F_D</math> is [[w:bijective|bijective]]. Assume furthermore that there exists a function <math>\beta</math>, the ''depth'', defined on <math>F</math> and <math>E(V,F)</math>, with values in <math>\mathbb{Z}_{\geq 0}</math> such that all the following properties hold:
# <math>\beta(f)=0</math> for all <math>f\in F_T</math>.
# <math>\beta(v)=0</math> for all <math>v\in V</math>.
# For all <math>(f,s)\in E(V,F)\setminus V</math>, <math>\beta((f,s))=\beta(f)</math>.
# For all <math>f\in F_D</math> the definition-like tuple <math>F^{-1}(f)=(n,l,e)</math> fulfils the property that <math>\beta(f)>\beta(e')</math> for all subexpressions <math>e'</math> of <math>e</math>. Specifically, <math>\beta(f)=\beta(e)+1</math>.
# For each <math>v\in V_D</math> there is exactly one <math>f\in F_D</math> such that for the definition-like tuple <math>F^{-1}(f)=(n,l,e)</math> the property <math>v\in A(e)</math> holds.
Then <math>D</math> is called a ''valid set of definitions'' for <math>F_D</math>.

'''Explanation.''' The definitions of JHilbert, user-defined via the <code>def</code> command fulfil the above properties of a valid set of definitions. When new <code>def</code> commands are evaluated, <math>F_D</math>, <math>V_U</math> and <math>V_D</math> are grown accordingly. Theorem 1 ensures that this is always possible. There are, of course, many valid sets of definitions. From now on, we shall assume <math>D</math> to be one arbitrary such set.

'''Lemma 12.''' The set <math>D</math> is finite.

{{sc|Proof.}} Since, <math>F</math> is finite, so is <math>F_D</math>. The finiteness of <math>D</math> now follows from the bijectivity of <math>F\colon D\to F_D</math>.

'''Lemma 13.''' If <math>f\in F_D</math> then <math>\beta(f)>0</math>.

{{sc|Proof.}} This follows from the definition of <math>\beta</math>.

'''Definition.''' Let <math>e\in E(V,F)</math>. Then we define the ''maximum depth'' of <math>e</math> as <math>\hat{\beta}(e):=\max\beta(e')</math>, where <math>e'</math> runs over all subexpressions of <math>e</math>.

'''Definition.''' Let <math>e=(f,(e_1,\ldots,e_m))\in E(V,F)\setminus V</math> be an expression such that <math>f\in F_D</math> and let <math>(n,(v_1,\ldots,v_m),e')=F^{-1}(f)</math>. Define the proper substitution map <math>u</math> by setting <math>u(v_i)=e_i</math> for <math>i=1,\ldots,m</math>. Then <math>\tilde{u}(e')</math> is called the ''unfolding'' of <math>e</math>.

'''Lemma 14.''' Let <math>e_1,e_2\in E(V,F)</math>. If <math>e_2</math> is the unfolding of <math>e_1</math> then <math>\beta(e_1)=\beta(e_2)+1</math> and <math>\hat{\beta}(e_1)\geq\hat{\beta}(e_2)</math>.

{{sc|Proof.}} Since <math>e_1</math> has an unfolding, it has a head functor which is a definition functor. The first claim now results from the definition of <math>\beta</math>. The second claim follows since by the definition of <math>D</math>, all apparent functors of <math>e_2</math> which are not apparent functors of <math>e_1</math> have lower depth than <math>e_1</math>.

'''Definition.''' Let <math>e\in E(V,F)</math>. Then we define the ''complete unfolding'' of <math>e</math>, <math>CUF(e)</math> recursively as follows.
# If <math>e\in V</math> then <math>CUF(e)=e</math>.
# If <math>e=(f,(e_1,\ldots,e_m))</math> with <math>f\in F_T</math> then <math>CUF(e)=(f,(CUF(e_1),\ldots,CUF(e_m)))</math>.
# If the head functor of <math>e</math> is a definition functor and <math>e'</math> is the unfolding of <math>e</math> then <math>CUF(e)=CUF(e')</math>.
Lemma 14 ensures that the recursion in this definition terminates.

'''Lemma 15.''' Let <math>e\in E(V,F)</math>. Then all apparent functors of <math>CUF(e)</math> are term functors. In other words, <math>\hat{\beta}(e)=0</math>.

{{sc|Proof.}} Due to the definition of <math>CUF</math>, <math>\beta(f)=0</math> for all apparent functors of <math>e</math>. Hence the claim follows from Lemma 13.

'''Definition.''' We denote the subset of <math>E(V,F)</math> of expressions all of whose apparent functors are term functors by <math>E(V,F_T)</math>.

'''Lemma 16.''' <math>CUF</math> is an [[w:idempotent|idempotent]] operation.

{{sc|Proof.}} Let <math>e\in E(V,F_T)</math>. By Lemma 15 it is sufficient to show that <math>CUF(e)=e</math>. If <math>|e|=1</math>, this follows by direct calculation. Assume the statement proven for expressions of length smaller than <math>|e|>1</math>. Then <math>e=(f,(e_1,\ldots,e_m))</math> and <math>CUF(e)=CUF((f,(e_1,\ldots,e_m)))=(f,CUF(e_1),\ldots,CUF(e_m))=(f,(e_1,\ldots,e_m))=e</math> by induction hypothesis.

'''Definition.''' Let <math>e_1,e_2\in E(V,F)</math>. Then <math>e_1</math> and <math>e_2</math> are called ''D-equivalent'' if <math>CUF(e_1)=CUF(e_2)</math>.

'''Lemma 17.''' D-equivalence is an equivalence relation.

{{sc|Proof.}} Reflexivity and symmetry are clear. Transitivity follows from the uniqueness of the complete unfolding.

'''Definition.''' Let <math>e\in E(V,F)</math>. Then we denote the equivalence class of <math>e</math> with respect to D-equivalence by <math>[e]_D</math> and the set of all equivalence classes by <math>E(V,F)_D</math>.

'''Lemma 18.''' <math>E(V,F_T)</math> is a set of representatives for <math>E(V,F)_D</math>.

{{sc|Proof.}} Let <math>C\in E(V,F)_D</math>. Since D-equivalence is an equivalence relation, <math>C\neq\emptyset</math>. Therefore there exists an <math>e\in C</math>. Now <math>CUF(e)</math> and <math>e</math> are D-equivalent and <math>CUF(e)\in E(V,F_T)</math> by Lemma 15. Now let <math>e'\in E(V,F_T)</math> be another representative for <math>C</math>. By definition of D-equivalence, <math>CUF(e')=CUF(CUF(e))</math>. Since <math>e'\in E(V,F_T)</math> and due to idempotence <math>e'=CUF(e)</math>. This proves the lemma.

'''Lemma 19.''' Let <math>u</math> be a proper substitution map and let <math>e\in E(V,F)</math>. Then <math>\tilde{u}(e)</math> and <math>\tilde{u}(CUF(e))</math> are D-equivalent.

{{sc|Proof.}} This is clear if <math>e\in V</math>. If <math>e=(f,(e_1,\ldots,e_m))</math> with <math>\beta(f)=0</math> then <math>CUF(\tilde{u}(e))=(f,(CUF(\tilde{u}(e_1)),\ldots,CUF(\tilde{u}(e_m))))</math>, by induction over <math>|e|</math>, <math>=(f,(CUF(\tilde{u}(CUF(e_1))),\ldots,CUF(\tilde{u}(CUF(e_m)))))=CUF(\tilde{u}(CUF(e)))</math>. For the case <math>\beta(f)>0</math> assume the statement proven for all expressions of depth shallower than <math>e</math>. Let <math>e'</math> be the unfolding of <math>e</math>, then <math>\tilde{u}(e')</math> is the unfolding of <math>\tilde{u}(e)</math>, in particular <math>\beta(\tilde{u}(e))>\beta(\tilde{u}(e'))</math> and hence <math>CUF(\tilde{u}(e))=CUF(\tilde{u}(e'))=CUF(\tilde{u}(CUF(e')))=CUF(\tilde{u}(CUF(e)))</math> by induction hypothesis.

'''Lemma 20.''' Let <math>u</math> be a proper substitution map. Then <math>\tilde{u}</math> is well-defined on <math>E(V,F)_D</math>.

{{sc|Proof.}} Let <math>e_1,e_2</math> be D-equivalent. Then by Lemma 19 and D-equivalence <math>CUF(\tilde{u}(e_1))=CUF(\tilde{u}(CUF(e_1)))=CUF(\tilde{u}(CUF(e_2)))=CUF(\tilde{u}(e_2))</math>. This implies the lemma.

'''Definition.''' Let <math>e\in E(V,F)</math>. Then a variable <math>v\in V</math> ''occurs'' in <math>e</math> if <math>v\in A(CUF(e))</math>. We denote the set of all variables occurring in <math>e</math> by <math>O(e)</math>.

'''Lemma 21.''' Let <math>e\in E(V,F)</math>. Then <math>O(e)\setminus V_D\subseteq A(e)</math>.

{{sc|Proof.}} By the definition of <math>D</math>, the only new variables an unfolding of a subexpression of <math>e</math> can incur are dummy variables.

'''Definition.''' Let <math>e_1,\ldots,e_m,e_1',\ldots,e_m'\in E(V,F)_D</math>. Assume there is a proper substitution map <math>u</math> such that <math>u(e_i)=e_i'</math> for all <math>i=1,\ldots,m</math>. Then the <math>e_1,\ldots,e_m</math> are called ''simultaneously [[w:unification|unifiable]]'' with the <math>e_1',\ldots,e_m'</math>.

=== DV constraints ===

'''Definition.''' Let <math>A</math> be a set and <math>R\subseteq A\times A</math>. Then <math>R</math> is called ''self-avoiding'' if <math>(x,x)\notin R</math> for all <math>x\in A</math>.

'''Definition.''' Let <math>R\subseteq A\times A</math>. Then the set <math>R\setminus\{(x,x):x\in A\}</math> is called the ''self-avoiding aperture'' of <math>R</math>.

'''Lemma 22.''' Let <math>R\subseteq A\times A</math>. Furthermore, let <math>R_1</math> be the symmetric closure of the self-avoiding aperture of <math>R</math> and <math>R_2</math> the self-avoiding aperture of the symmetric closure of <math>R</math>. Then <math>R_1=R_2</math>.

{{sc|Proof.}} Let <math>(x,y)\in R_1</math>. Then <math>(x,y)\in R\setminus\{(x,x):x\in A\}</math> or <math>(y,x)\in R\setminus\{(x,x):x\in A\}</math>. In particular <math>x\neq y</math> and <math>(x,y)\in R</math> or <math>(y,x)\in R</math>. Therefore <math>(x,y)</math> is an element of the symmetric closure of <math>R</math>. Since <math>x\neq y</math>, <math>(x,y)\in R_2</math>. If, on the other hand, <math>(x,y)\in R_2</math>, then <math>x\neq y</math> and <math>(x,y)\in R</math> or <math>(y,x)\in R</math>. Therefore <math>(x,y)\in R_1</math>

'''Definition.''' A symmetric, self-avoiding relation on <math>V</math> is called a ''DV constraint''. A DV constraint on <math>V_N</math> is called a ''named DV constraint'' and a DV constraint on <math>V_U</math> is called an ''unnamed DV constraint''.

'''Definition.''' Let <math>\Delta</math> be a DV constraint. Then we define the set <math>A(\Delta):=\{v\in V:\exists w\in V:(v,w)\in\Delta\}</math>. Furthermore, if <math>W\subseteq V</math>, we define <math>\Delta_W:=\bigcup\limits_{\Delta'\subseteq\Delta}\Delta'</math>, where <math>\Delta'</math> runs over those DV constraints with <math>A(\Delta')\subseteq W</math>, the ''restriction'' of <math>\Delta</math> to <math>W</math>.

'''Lemma 23.''' Each restriction of a DV constraint is again a DV constraint, as is the union of two DV constraints. The same holds for named and unnamed DV constraints, respectively.

{{sc|Proof.}} This follows since the union of two self-avoiding relations is self-avoiding, and likewise the union of two symmetric relations is again symmetric.

'''Definition.''' Let <math>u</math> be a proper substitution map and <math>R\subseteq V\times V</math>. Then we extend <math>\tilde{u}</math> to <math>R</math> by <math>\tilde{u}(R):=\bigcup\limits_{(v,w)\in R}A(v)\times A(w)</math>.

'''Lemma 24.''' Let <math>R\subseteq V\times V</math> be a symmetric relation and <math>u</math> a proper subtitution map. Then <math>\tilde{u}(R)</math> is also a symmetric relation.

{{sc|Proof.}} Let <math>(v,w)\in \tilde{u}(R)</math>, then there is a <math>(v',w')\in R</math> such that <math>(v,w)\in A(v')\times A(w')</math>. Now, <math>R</math> is symmetric, so <math>(w',v')\in R</math> and thus <math>A(w')\times A(v')\subseteq\tilde{u}(R)</math>. This proves the lemma.

Note that the application of a proper substitution map to a DV constraint does not ncessarily yield a DV constraint.

=== Statements ===

'''Definition.''' A tuple <math>s=(n,\Delta,h,e)</math> with <math>n\in N</math>, <math>\Delta</math> a DV constraint, <math>h\in E(V,F)^*</math> and <math>e\in E(V,F)</math> is a ''statement'' if the following additional properties are fulfilled:
* <math>A(e)\subseteq V_U</math> and <math>A(e')\subseteq V_U</math> for all <math>e'</math> in <math>h</math>. In other words, <math>A(s)\subseteq V_U</math>, where we define <math>A(s):=A(e)\cup\bigcup\limits_{k=1}^{|h|}A(h_k)</math>,
* <math>A(\Delta)\subseteq A(s)</math>.
We we define the ''name'', <math>A(s):=n</math>, the ''DV constraints'' <math>DV(s):=\Delta</math>, the ''hypotheses'' <math>H(s):=h</math>, the ''number of hypotheses'' <math>NH(s):=|h|</math>, the <math>i</math>-th ''hypothesis'' <math>H_i(s)</math> as the <math>i</math>-th projection of <math>H(s)</math>, for <math>i=1,\ldots,NH(s)</math>, and the ''consequent'' <math>C(s):=e</math>.
If <math>s</math> fulfils precisely the same properties except that <math>V_U</math> is replaced by <math>V_N</math> then <math>s</math> is called a ''pending statement''.

'''Definition.''' A finite set <math>S</math> is called a ''permissible set of statements'' if all elements of <math>S</math> are statements and the restriction of the name projection <math>N</math> to <math>S</math> is injective.

'''Lemma 25.''' Let <math>S</math> be a permissible set of statements. Then any <math>S'\subseteq S</math> is also a permissible set of statements.

{{sc|Proof.}} The proof is similar to the proof of Lemma 2.

'''Definition.''' Let <math>s</math> be a (pending) statement and let <math>u</math> be a proper substitution map. Now define
* <math>s':=N(s)</math>,
* <math>\Delta':=\tilde{u}(DV(s))</math>,
* <math>h_i':=\tilde{u}(H_i(s))</math> for all <math>i=1,\ldots,NH(s)</math>,
* <math>c':=\tilde{u}(C(s))</math>.
We extend <math>\tilde{u}</math> to <math>s</math> by setting <math>\tilde{u}(s):=s'</math>.

'''Lemma 26.''' Let <math>s</math> be a pending statement and let <math>u\colon A(s)\to V_U</math> be an injective proper substitution map. Then <math>\tilde{u}(s)</math> is a statement. We call such a statement an ''anonymisation'' of <math>s<math>.

{{sc|Proof.}} Since <math>u</math> is injective and its [[w:codomain|codomain]] is contained in <math>V_U</math>, <math>\tilde{u}(DV(s))</math> is self-avoiding and therefore a DV constraint by lemma 24. The remainder of the lemma is clear.

'''Explanation.''' First, statements are user-defined in JHilbert using the <code>stmt</code> and <code>thm</code> commands (where the <code>thm</code> statements have first to be derived as defined below). The user writes the statements as pending statements which are subsequently anonymised by introducing new unnamed variables that replace the named ones in the pending statement.

'''Definition.''' Let <math>s</math> be a pending statement and <math>e\in E(V,F)_D</math>. Assume there is a <math>W\subseteq V</math> with <math>W\cap A(s)=\emptyset</math> and an injective map <math>u\colon W\to V\setminus A(s)</math> which is a proper substitution map such that <math>\tilde{u}(e)=[C(s)]_D</math>. Then <math>C(s)</math> and <math>e</math> are called ''V-equivalent'' (with respect to <math>s</math>).

Note that V-equivalence is not an equivalence relation on <math>E(V,F)</math> (or <math>E(V,F)_D</math>) because it is a relation between different sets. Furthermore, the actual equivalence depends on the apparent variables in the statement. However, we can say that V-equivalence is coarser than D-equivalence in the following sense.

'''Lemma 27.''' Let <math>s</math> be a pending statement and let <math>e\in E(V,F)</math> be D-equivalent to <math>C(s)</math>. Then <math>C(s)</math> and <math>[e]_D</math> are V-equivalent.

{{sc|Proof.}} D-equivalence implies <math>[e]_D=[C(s)]_D</math>. Hence the requirement <math>\tilde{u}([e]_D)=[C(s)]_D</math> is fulfilled by an empty map <math>u</math>. Clearly, such a map fulfils the further requirements of V-equivalence. This proves the statement.

'''Definition.''' Let <math>S</math> be a permissible set of statements and let <math>s</math> be a pending statement. Then we define the ''closure'' of <math>s</math> with respect to <math>S</math>, denoted by <math>Cl_S(s)</math>, to be the smallest subset of <math>E(V,F)_D</math> such that
# <math>[H_i(s)]_D\in Cl_S(s)</math> for all <math>i=1,\ldots,NH(s)</math>,
# For all <math>s'\in S</math> and all proper substitution maps <math>u\colon V_U\to V_N</math>, <math>\tilde{u}([C(s')]_D)\in Cl_S(s)</math> whenever all of the following are true:
:* <math>\tilde{u}([H_i(s')]_D)\in Cl_S(s)</math> for all <math>i=1,\ldots,NH(s')</math>.
:* For all <math>(v,w)\in DV(s')</math>, the symmetric closure of <math>A(\tilde{u}(v))\times A(\tilde{u}(w))</math> is a DV constraint. Its restriction to <math>\bigcup\limits_{i=1}^{NH(s)}A(H_i(s))\cup A(\tilde{u}(C(s')))</math> is a subset of <math>DV(s)</math>.
The pending statement <math>s</math> is called ''provable from <math>S</math>'' if there is an <math>e\in Cl_S(s)</math> such that <math>C(s)</math> and <math>e</math> are V-equivalent.

'''Definition.''' Let <math>S</math> be a permissible set of statements and let <math>s</math> be a pending statement. Then we define the family <math>(Cl_S(s)_k)_{k\in\mathbb{Z}_{\geq 0}}</math> recursively as follows.
# <math>Cl_S(s)_0:=\{[H_i(s)]_D\}_{i=1}^{NH(s)}</math>.
# For all <math>s'\in S</math> and all proper substitution maps <math>u\colon V_U\to V_N</math>, <math>\tilde{u}([C(s')]_D)\in Cl_S(s)_k</math> whenever all of the following are true:
:* <math>\tilde{u}([H_i(s')]_D)\in\bigcup\limits_{j=0}^{k-1}Cl_S(s)_j</math> for all <math>i=1,\ldots,NH(s')</math>.
:* For all <math>(v,w)\in DV(s')</math>, the symmetric closure of <math>A(\tilde{u}(v))\times A(\tilde{u}(w))</math> is a DV constraint. Its restriction to <math>\bigcup\limits_{i=1}^{NH(s)}A(H_i(s))\cup A(\tilde{u}(C(s')))</math> is a subset of <math>DV(s)</math>.

'''Lemma 28.''' Let <math>S</math> be a permissible set of statements and let <math>s</math> be a pending statement. Then <math>Cl_S(s)=\bigcup\limits_{k\in\mathbb{Z}_{\geq 0}}Cl_S(s)_k</math>.

{{sc|Proof.}} The inclusion <math>\bigcup\limits_{k\in\mathbb{Z}_{\geq 0}}Cl_S(s)_k\subseteq Cl_S(s)</math> is clear due to the definition of closure. On the other hand,  <math>\bigcup\limits_{k\in\mathbb{Z}_{\geq 0}}Cl_S(s)_k</math> already fulfils the properties of a closure, so equality follows from the minimality requirement.

'''Lemma 29.''' Let <math>S</math> be a permissible set of statements, <math>s</math> a pending statement and <math>u</math> a proper substitution map such that <math>\tilde{u}(s)</math> is also a pending statement. Then <math>\tilde{u}(Cl_S(s))\subseteq Cl_S(\tilde{u}(s))</math>.

{{sc|Proof.}} By definition, <math>\tilde{u}(Cl_S(s)_0)=Cl_S(\tilde{u}(s))_0</math>. Now let <math>k>0</math> and assume that we have already proven that <math>\tilde{u}(Cl_S(s)_l)\subseteq Cl_S(\tilde{u}(s))</math> for <math>l=0,\ldots,k-1</math>. Let <math>e\in\tilde{u}(Cl_S(s)_k)</math>. Then there is an <math>e'\in Cl_S(s)_k</math> such that <math>\tilde{u}(e')=e</math>. Let <math>s'\in S</math> be the statement and <math>u'</math> be the proper substitution map from which <math>e'</math> arises. Then <math>\tilde{u}(\tilde{u}'([H_i(s')]_D))\in Cl_S(\tilde{u}(s))</math> by induction hypothesis. Furthermore <math>\tilde{u}'(DV(s'))\subseteq DV(s)</math> and thus <math>\tilde{u}(\tilde{u}'(DV(s'))\subseteq\tilde{u}(DV(s))=DV(\tilde{u}(s))</math>. Therefore <math>e=\tilde{u}(e')=\tilde{u}(\tilde{u}'([Cl_S(s')]_D))\in Cl_S(\tilde{u}(s))</math>. The claim now follows from lemma 28.

'''Lemma 30.''' Let <math>S</math> be a permissible set of statements and let <math>s</math> be a pending statement. Then for all <math>e\in Cl_S(s)</math> and all injective proper substitution maps <math>u\colon V_N\setminus A(s)\to V_N\setminus A(s)</math>, <math>\tilde{u}(e)\in Cl_S(s)</math>.

'''Proof.''' Since <math>A(s)</math> is excluded from the [[w:codomain|codomain]] of <math>u</math>, such a substitution cannot introduce new invalid DV constraints. <math>\tilde{u}</math> acts identically on <math>Cl_S(s)_0</math> since <math>A(s)</math> is excluded from the [[w:domain of a function|domain]] of <math>u</math>. This proves the statement for all <math>e\in Cl_S(s)_0</math>. Now assume the statement proven for all <math>e\in\bigcup\limits_{j=0}^{k-1}Cl_S(s)_j</math> for some <math>k>0</math>. Let <math>e\in Cl_S(s)_k</math>. Furthermore, let <math>s'\in S</math> be the statement and <math>u'</math> be the proper substitution map from which <math>e</math> arises. Now, <math>\tilde{u}([\tilde{u}'(H_i(s'))]_D)\in Cl_S(s)</math> for all <math>i=1,\ldots,NH(s')</math> by induction hypothesis. Since <math>u</math> is injective and maps named variables to named variables, <math>u\circ u'</math> is also a proper substitution map. Therefore <math>\tilde{u}(e)=\tilde{u}(\tilde{u}'([C(s')]_D))\in Cl_S(s)</math>. So by induction and lemma 28, the statement follows.

'''Lemma 31.'''  Let <math>S</math> be a permissible set of statements and let <math>s</math> be a pending statement which is provable from <math>S</math>. Then <math>[C(s)]_D\in Cl_S(s)</math>.

{{sc|Proof.}} Since <math>s</math> is provable from <math>S</math>, <math>C(s)</math> is V-equivalent to some <math>e\in Cl_S(s)</math>. Let <math>u</math> be the V-equivalence map. Then <math>\tilde{u}(e)=[C(s)]_D</math>. The statement now follows from lemma 28 because <math>u</math> is injective and its domain and codomain exclude <math>A(s)</math>.

'''Lemma 32.''' Let <math>S_1</math> be a permissible set of statements, <math>s_1\in S_1</math> and set <math>S_2:=S_1\setminus\{s_1\}</math> (which is a permissible set of statements by lemma 25). Let <math>s_2</math> be a pending statement which is provable from <math>S_2</math> such that <math>s_1</math> is an anonymisation of <math>s_2</math>. Then all pending statements <math>s</math> which are provable from <math>S_1</math> are also provable from <math>S_2</math>.

{{sc|Proof.}} For all pending statements <math>s</math>, we have <math>Cl_{S_1}(s)_0=Cl_{S_2}(s)_0\subseteq Cl_{S_2}(s)</math> by lemma 28. Now assume we have already proven that <math>\bigcup\limits_{j=0}^{k-1}Cl_{S_1}(s)_j\subseteq Cl_{S_2}(s)</math> for some <math>k>0</math>. Let <math>e\in Cl_{S_1}(s)_k</math> and let <math>s'\in S_1</math> be the statement and <math>u</math> be the proper substitution map from which <math>e</math> arises. Then <math>\tilde{u}([H_i(s')]_D)\in Cl_{S_2}(s)</math> by induction hypothesis. So if <math>s'\in S_2</math> it follows that <math>e\in Cl_{S_2}(s)</math>. If not, then <math>s'=s_1</math>. Let <math>u_1</math> be an anonymisation map which transports <math>s_2</math> to <math>s_1</math>. Now, <math>s_2</math> is provable from <math>S_2</math>, so <math>[C(s_2)]_D\in Cl_{S_2}(s_2)</math> by lemma 31. Then <math>e=\tilde{u}(\tilde{u}_1([C(s_2)]_D))\in\tilde{u}(\tilde{u}_1(Cl_{S_2}(s_2)))</math>, by lemma 29, <math>\subseteq Cl_{S_2}(\tilde{u}(s'))\subseteq Cl_{S_2}(s)</math>. The statement now follows from lemma 28.

== Implementation of Metamath first order logic in JHilbert ==

In this section we implement the first order logic part of the Metamath proof explorer <ref name="megill">{{sc|N. Megill}}, Metamath Proof Explorer, http://us.metamath.org/mpegif/mmset.html</ref> in JHilbert. Our interface is as follows:
 kind (set)
 kind (class)
 kind (wff)
 
 var (set x y z)
 var (wff φ χ ψ)
 
 term (class (cv set))
 term (wff (= class class))
 term (wff (∈ class class))
 term (wff (¬ wff))
 term (wff (→ wff wff))
 term (wff (∀ set wff))
 
 stmt (ax-mp () (φ (φ → χ)) χ)
 stmt (ax-gen () (φ) (∀ x φ))
 stmt (ax-1 () () (φ → (χ → φ)))
 stmt (ax-2 () () ((φ → (χ → ψ)) → ((φ → χ) → (φ → ψ))))
 stmt (ax-3 () () (((¬ φ) → (¬ χ)) → (χ → φ)))
 stmt (ax-4 () () ((∀ x φ) → φ))
 stmt (ax-5 () () ((∀ x (φ → χ)) → ((∀ x φ) → (∀ x χ))))
 stmt (ax-6 () () ((¬ (∀ x φ)) → (∀ x (¬ (∀ x φ)))))
 stmt (ax-7 () () ((∀ x (∀ y φ)) → (∀ y (∀ x φ))))
 stmt (ax-8 () () (((cv x) = (cv y)) → (((cv x) = (cv z)) → ((cv y) = (cv z)))))
 stmt (ax-9 () () (¬ (∀ x (¬ ((cv x) = (cv y))))))
 stmt (ax-10 () () ((∀ x ((cv x) = (cv y))) → (∀ y ((cv y) = (cv x)))))
 stmt (ax-11 () () (((cv x) = (cv y)) → ((∀ x φ) → (∀ x (((cv x) = (cv y)) → φ)))))
 stmt (ax-12 () () ((¬ (∀ z ((cv z) = (cv x)))) → ((¬ (∀ z ((cv z) = (cv y)))) →
  (((cv x) = (cv y)) → (∀ z ((cv x) = (cv y)))))))
 stmt (ax-13 () () (((cv x) = (cv y)) → (((cv x) ∈ (cv z)) → ((cv y) ∈ (cv z)))))
 stmt (ax-14 () () (((cv x) = (cv y)) → (((cv z) ∈ (cv x)) → ((cv z) ∈ (cv y)))))
 stmt (ax-15 () () ((¬ (∀ z ((cv z) = (cv x)))) → ((¬ (∀ z ((cv z) = (cv y)))) →
  (((cv x) ∈ (cv y)) → (∀ z ((cv x) ∈ (cv y)))))))
 stmt (ax-17 ((φ x)) () (φ → (∀ x φ)))
Note that we do not need <code>ax-16</code> due to <code>ax-17</code> [http://us.metamath.org/mpegif/ax-16.html]. Also note that we do not need any variables of kind <code>class</code>.

From now on we consider some JHilbert proof module which imports only the above interface but otherwise has arbitrary valid content. In what follows we shall make frequent references to the formalisation of Metamath as done in Appendix C of the Metamath book<ref name="metamath">{{sc|N. Megill}}, The Metamath Book, http://us.metamath.org/downloads/metamath.pdf</ref>.

'''Definition.''' Let <math>CN:=\{(,),\mathrm{set},\mathrm{class},\mathrm{wff},=,\in,\neg,\rightarrow,\forall,\vdash\}</math>, <math>VR:=V</math>, <math>T:=\{(t,v):v\in VR, t=K(v)\}</math> (in particular, the first component of all elementf of <math>T</math> is one of <math>\mathrm{set},\mathrm{class},\mathrm{wff}</math>), and let <math>\Gamma</math> be the set of Metamath statements representing the functors and axioms given above (except <code>cv</code>, which is unnecessary in Metamath). We shall then consider the ''Metamath formal system'' <math>\mathfrak{F}:=(CN,VR,\Gamma)</math>. We denote the Metamath universe of <math>\mathfrak{F}</math> by <math>\mathfrak{U}</math>.

'''Definition.''' We denote the mapping from JHilbert statements <math>s=(n,\Delta,h,e)</math> to Metamath statements <math>(D_M,T_M,H,A)</math> by <math>MM</math>. If <math>h\in E(V,F_T)^*</math> and <math>e\in E(V,F_T)</math>, then <math>MM</math> maps as expected. In the general case, <math>MM</math> maps so that if <math>h=(e_1,\ldots,e_m)</math>, then <math>H=(MM(CUF(e_1)),\ldots,MM(CUF(e_m))</math>, and <math>A=MM(CUF(e))</math>. In addition, for each dummy variable <math>d</math> appearing in <math>CUF(e_1),\ldots,CUF(e_m),CUF(e)</math>, all unordered pairs <math>\{d,v\}</math> where <math>v\in VR\setminus\{d\}</math> are added to <math>D</math>.

'''Example.''' <math>MM(\texttt{ax-11})=(\emptyset,\{(\mathrm{set},x),(\mathrm{set},y),(\mathrm{wff},\varphi)\},\emptyset,\vdash (x=y\rightarrow(\forall x\varphi\rightarrow\forall x(x=y\rightarrow\varphi))))</math>.

== Soundness of JHilbert ==

In order to prove the soundness of JHilbert, we must show that each pending JHilbert statement for which a JHilbert proof exists, is provable in Metamath as well (this proves soundness under the assumption that Metamath is sound as well). This means that for each provable JHilbert statement <math>s</math> we must show that <math>MM(s)\in\mathfrak{U}</math>. Essentially, we show this by induction over the minimum number of steps a proof must have.

'''Definition.''' Let <math>S:=(D,T,H,A)</math> be a Metamath pre-statement. Then we define a family <math>(Cl(S)_k)_{k\in\mathbb{Z}_{\geq 0}}</math> recursively as follows.
# <math>Cl(S)_0:=T\cup H</math>.
# If for some <math>(D_M',T_M',H',A')\in\Gamma</math> and some Metamath substitution <math>\sigma</math> we have <math>\sigma(T_M'\cup H')\subseteq Cl(S)_{k-1}</math>, and for all <math>\{\alpha,\beta\}\in D_M'</math>, <math>\gamma\in\mathcal{V}(\sigma(\alpha))</math>, <math>\delta\in\mathcal{V}(\sigma(\beta))</math> we have <math>\{\gamma,\delta\}\in D</math>, then <math>\sigma(A')\in Cl(S)_k</math>.
# Nothing else is in <math>Cl(S)_k</math>.

'''Lemma 26.''' Let <math>S:=(D,T,H,A)</math> be a Metamath pre-statement and let <math>Cl(S)</math> be the closure of <math>S</math>. Then <math>Cl(S)=\bigcup\limits_{k\in\mathbb{Z}_{\geq 0}}Cl(S)_k</math>.

{{sc|Proof.}} The inclusion <math>\bigcup\limits_{k\in\mathbb{Z}_{\geq 0}}Cl(S)_k\subseteq Cl(S)</math> is clear from the definition of closure. On the other hand, <math>\bigcup\limits_{k\in\mathbb{Z}_{\geq 0}}Cl(S)_k</math> already fulfils the definition of closure. The minimality property of the closure implies the wanted equality.

'''Definition.''' Let <math>s</math> be a pending JHilbert statement and let <math>ps:=(p_0,\ldots,p_m)</math> be a sequence of proofs in progress such that <math>p_0=(\emptyset,\epsilon)</math>, <math>p_m</math> is a proof for <math>s</math>, and each element of <math>s</math> other than <math>p_0</math> is generated by the previous element by one of the recursion steps in the definition of a proof in progress. Then <math>ps</math> is called a ''valid sequence of proof steps'' for <math>s</math>. Obviously, each provable JHilbert statement has a valid sequence of proof steps.

'''Lemma 27.''' Let <math>s</math> be a pending JHilbert statement and let <math>ps:=(p_0,\ldots,p_m)</math> be a valid sequence of proof steps for <math>s</math>. Then <math>ps</math> can be altered in such a way that all proof steps in <math>ps</math> which invoke a statement, that statement is one of the axioms.

{{sc|Proof.}} Assume <math>p_k</math> is the first proof step in <math>ps</math> invoking a theorem that is not an axiom. Let <math>ps':=(p_0',\ldots,p_{m'}')</math> be a valid sequence of proof steps for this theorem. Furthermore, let <math>ps_i=(p_1,\ldots,p_i)</math> for <math>i=0,\ldots,k-1</math>. Now take every step of <math>ps'</math> which invokes a hypothesis and replace it by <math>ps_i</math>, where <math>i</math> is the hypothesis number. This number is always smaller than <math>k</math>, or otherwise the theorem would not be applicable in <math>p_k</math> as the number of expressions in a proof in progress can increase by at most one in each step. Also note that we can append <math>ps_i</math> anywhere and we have still a valid sequence of proof steps. Steps not being a hypothesis remain as they are. This is always valid since the nature of the V-equivalence map does not encumber unifiability. Finally, append <math>(p_{k+1},\ldots,p_m)</math>. By repeating this procedure a finite number of times, we end up with a proof consisting only of hypotheses and axioms. The new DV constraints may contain more elements than before, but only through dummy variables and V-equivalence. Therefore, the restriction <math>\Delta_W</math> remains the same.

Due to this lemma, we shall from now on assume that a valid sequence of proof steps for some pending JHilbert statement arises only through hypothesis and axiom invocations.

'''Definition.''' Let <math>s</math> be a pending JHilbert statement and let <math>ps</math> be a valid sequence of proof steps for <math>s</math>. Then we call the number of axiom invocations in <math>ps</math> the ''complexity'' of <math>ps</math>.


<!--FIXME: cruft below -->

'''Lemma 26.''' Let <math>s</math> be a pending statement for which a JHilbert proof exists that consists of only one step which is a hypothesis step. Then there is a Metamath proof for <math>MM(s)</math>.

{{sc|Proof.}} The complete JHilbert proof has the form <math>(\emptyset,(e))</math>, where <math>C(s)</math> and <math>e</math> are V-equivalent. Let <math>u</math> be the variable mapping for V-equivalence. Now consider a pending statement <math>s'</math> with <math>DV(s')=DV(s)</math>, <math>H(s')=H(s)</math> and <math>C(s')\in e</math>. Such a pending statement exists because <math>e</math> is the equivalence class of a hypothesis <math>e'</math> of <math>s</math> and hence <math>A(e')\subseteq V_N</math>. Then <math>CUF(C(s'))=CUF(e)</math>, so <math>MM(s')</math> is provable in Metamath by simply invoking the hypothesis <math>MM(e)</math>. Now, the DV constraints of <math>MM(s')</math> are the images of <math>DV(s)</math> under the metamath variable mapping (let's call it <math>MV'</math>), plus the additional constraints for dummy variables. The DV constraints of <math>MM(s)</math> are also the images of <math>DV(s)</math> under that statement's Metamath variable mapping (denote it by <math>MV</math>), plus additional constraints for possibly other dummy variables. Clearly, the variables of <math>s'</math> are a subset of the variables of <math>s</math>, so since <math>MV'</math> is injective and <math>\tilde{u}</math> maps variables to variables, we can define the injective mapping <math>F:=MV\circ\tilde{u}\circ MV^{\prime-1}</math>. Then the image of the variables of <math>MM(s')</math> under <math>F</math> is a subset of the variables of <math>MM(s)</math>. In particular, the DV constraints of <math>MM(s)</math> are more restrictive than the ones of <math>MM(s')</math>, so we can prove <math>MM(s)</math> simply by invoking <math>MM(s')</math> with the variables obtained by applying <math>F</math>.

'''Lemma 27.''' The Metamath mapping <math>MM(s)</math> for each of the statements <code>ax-mp</code>, <code>ax-gen</code>, <code>ax-1</code> through <code>ax-15</code> and <code>ax-17</code> (regarded as pending statements) is provable in Metamath.

{{sc|Proof.}} By their nature, these axioms map precisely to their Metamath counterparts, except possibly with different variable names which can be rectified by invoking the corresponding original Metamath axiom with the correct variables (or by choosing <math>MV</math> to be the correct variable mapping in the first place). In particular, there are no dummy variables at all.

'''Lemma 28.''' Let <math>s_1,\ldots,s_l</math> be statements such that <math>MM(s_i)</math> is provable in Metamath for <math>i=1,\ldots,l</math>. Let <math>s</math> be a pending statement such that there is a JHilbert proof for <math>s</math> all of whose proof steps are either hypotheses or one of the statements <math>s_1,\ldots,s_l</math>. Then <math>MM(s)</math> is provable in Metamath.

{{sc|Proof.}} Let <math>(\Delta,(e))</math> be the JHilbert proof for <math>s</math> and let <math>MV</math> be the Metamath variable mapping for <math>MM(s)</math>. Consider first the case that <math>C(s)\in e</math>.

'''Lemma 28.''' Let <math>s'</math> be a statement such that <math>MM(s')</math> is provable in Metamath and let <math>s</math> be a pending statement such that there is a JHilbert proof for <math>s</math> achievable in only one proof step, namely <math>s'</math>. Then <math>MM(s)</math> is provable in Metamath.

{{sc|Proof.}} Let <math>(\Delta,(e))</math> be the JHilbert proof for <math>s</math>. Since it is achievable in only one step, <math>H(s')=\epsilon</math>. Now, there is a proper substitution map <math>u</math> such that <math>[\tilde{u}(C(s'))]_D=e</math>. Furthermore, <math>\Delta</math> is the symmetric closure of the union of all <math>A(\tilde{u}(v_1))\times A(\tilde{u}(v_2))</math>, <math>(v_1,v_2)\in DV(s')</math>. Now assume <math>C(s)\in e</math>. Then the only variables which can appear in <math>\Delta</math> without being apparent in <math>s</math> are the dummy variables of the hypotheses and the consequent of <math>s</math>. Since <math>MM(s)</math> provides for maximal DV constraints for those dummies by definition, <math>MM(s)</math> is provable in metamath by invoking <math>MM(s')</math>. If <math>C(s)\notin e</math>, then <math>C(s)</math> and <math>e</math> are still V-equivalent. Let <math>u</math> be the V-equivalence mapping. By definition, <math>u</math> is injective. Now let <math>v</math> be a variable appearing in <math>\Delta</math> which is not apparent in the hypotheses or the consequent of <math>s</math>. Then there must occur some dummy <math>d</math> in the hypotheses or the consequent of <math>s</math> such that <math>u^{-1}(d)=v</math>. The provability of <math>MM(s)</math> now follows as in the proof of Lemma 26.

'''Proposition 1.''' All JHilbert statements proved with at most one proof step from the axioms are provable in Metamath.

{{sc|Proof.}} This is the combination of lemma 26, 27, and 28.

'''Hypothesis.''' Let <math>k\in\mathbb{Z}_{>0}</math> be arbitrary but fixed. Assume that all JHilbert statements proved with at most <math>k</math> proof steps from the axioms are provable in Metamath.

'''Lemma 29.''' Assume the JHilbert statement <math>s</math> has a proof consisting of more than just one proof step. Then the last step in such a proof is not a hypothesis step.

{{sc|Proof.}} After each proof step, the proof in progress has the form <math>(\Delta,(e_1,\ldots,e_m))</math> with <math>m\geq 1</math>. So after the next-to-last proof step, we have <math>m\geq 1</math>. If the last proof step were a hypothesis, we would end up with a proof in progress that has <math>m\geq 2</math>. Such a proof in progress, however, is not a proof.

'''Lemma 30.''' Let <math>s'</math> be a statement such that <math>MM(s')</math> is provable in Metamath and let <math>s</math> be a pending statement such that there is a JHilbert proof for <math>s</math> achievable in only one proof step, namely s'. Then MM(s) is provable in Metamath. 

== References ==

<references />